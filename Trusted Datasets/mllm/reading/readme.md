# Reading Items

- [ ] [RLHF roundup: Getting good at PPO, sketching RLHF’s impact, RewardBench retrospective, and a reward model competition](https://www.interconnects.ai/p/rlhf-roundup-2024?publication_id=48206&post_id=146002205&isFreemail=true&r=2b77bo&triedRedirect=true)
- [ ] [RLHF progress: Scaling DPO to 70B, DPO vs PPO update, Tülu 2, Zephyr-β, meaningful evaluation, data contamination](https://www.interconnects.ai/p/rlhf-progress-scaling-dpo-to-70b)
- [ ] [Training Open Instruction-Following Language Models](https://github.com/allenai/open-instruct)
- [ ] [TRL - Transformer Reinforcement Learning](https://github.com/huggingface/trl/tree/7965b7834052ab3d60a1cc5de382e2f56b3772e7)
