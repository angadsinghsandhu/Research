{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLzoIqEKOeBL"
      },
      "source": [
        "# Intelligent AI ChatBot in Python (NeuralNine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "6sO3gMjUOX3c"
      },
      "outputs": [],
      "source": [
        "# Intelligent AI ChatBot in Python\n",
        "# this is going to dyamically understand and respond to greetings\n",
        "# but the responses will be static\n",
        "\n",
        "# our files will be : intents.json, responses.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7d-9Af8bLE6"
      },
      "source": [
        "## TRAINING CHATBOT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H2IXX6Db-uh",
        "outputId": "e8c9a186-8496-4dab-9a7e-822236a0f8bb"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import random\n",
        "import json\n",
        "import pickle   # for serialization\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "\n",
        "import nltk\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# getting intents from database\n",
        "conn = sqlite3.connect(\"intents.sqlite\")\n",
        "cur = conn.cursor()\n",
        "\n",
        "intents = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'tag': 'greetings'}, {'tag': 'goodbye'}, {'tag': 'age'}, {'tag': 'name'}, {'tag': 'shop'}, {'tag': 'hours'}, {'tag': 'crop'}, {'tag': 'stocks'}]\n"
          ]
        }
      ],
      "source": [
        "sql_statement = '''\n",
        "SELECT t.id, t.name FROM tags AS t;\n",
        "'''\n",
        "intents = list(map(lambda x: {\"tag\": x[1]}, cur.execute(sql_statement).fetchall()))\n",
        "print(intents)\n",
        "# for i in cur.execute(sql_statement).fetchall():\n",
        "#     print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'tag': 'greetings', 'pattern': ['hello', 'hey', 'hi', 'good day', 'good morning'], 'responses': ['Hello', 'What can I do for you?']}\n",
            "{'tag': 'goodbye', 'pattern': ['cya', 'see you later', \"I'm leaving\", 'goodbye', 'have a good day', 'I am leaving', 'bye', 'see ya'], 'responses': ['Goodbye', 'Nice to have met you']}\n",
            "{'tag': 'age', 'pattern': ['how old', 'how old is florian', 'what is your age', 'how old are you?', 'age?'], 'responses': ['My owner is 21 years old!', '21 years!', '21']}\n",
            "{'tag': 'name', 'pattern': ['What is your name', 'what should I call you?', 'what is your name', 'who are you', 'can you tell me your name'], 'responses': ['You can call me Neural!', \"I'm neural\", \"I'm Neural, The assistant\"]}\n",
            "{'tag': 'shop', 'pattern': [\"I'd like to buy something\", 'What are your products?', 'what do you recommend?', 'What are you selling?'], 'responses': ['We sell books! Lots of them.']}\n",
            "{'tag': 'hours', 'pattern': ['When are you guys open?', 'What are your hours', 'hours of operation', 'price', 'value', 'mrp'], 'responses': ['24/7']}\n",
            "{'tag': 'crop', 'pattern': ['What is the price of maize', 'How much is Wheat worth', 'selling price of rice'], 'responses': ['[Unavailable]']}\n",
            "{'tag': 'stocks', 'pattern': ['what stocks do I own?', 'how are my shares?', 'what companies am I invested in?', 'What am I doing in stocks'], 'responses': ['You own the following shares: ABBV, APPL, FB, NVDA and an ETF of the S&P 500 Index!']}\n"
          ]
        }
      ],
      "source": [
        "for idx, i in enumerate(intents):\n",
        "    tag = i['tag']\n",
        "\n",
        "    sql_pat = '''\n",
        "    SELECT t.id, t.name, p.name FROM tags AS t JOIN patterns AS p ON t.id == p.tag_id WHERE t.name == '{}';\n",
        "    '''.format(tag)\n",
        "\n",
        "    sql_res = '''\n",
        "    SELECT t.id, t.name, r.name FROM tags AS t JOIN responses AS r ON t.id == r.tag_id WHERE t.name == '{}';\n",
        "    '''.format(tag)\n",
        "\n",
        "    intents[idx]['pattern'] = list(map(lambda x: x[2], cur.execute(sql_pat).fetchall()))\n",
        "    intents[idx]['responses'] = list(map(lambda x: x[2], cur.execute(sql_res).fetchall()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "greetings\n",
            "['hello', 'hey', 'hi', 'good day', 'good morning']\n",
            "['Hello', 'What can I do for you?']\n",
            "\n",
            "goodbye\n",
            "['cya', 'see you later', \"I'm leaving\", 'goodbye', 'have a good day', 'I am leaving', 'bye', 'see ya']\n",
            "['Goodbye', 'Nice to have met you']\n",
            "\n",
            "age\n",
            "['how old', 'how old is florian', 'what is your age', 'how old are you?', 'age?']\n",
            "['My owner is 21 years old!', '21 years!', '21']\n",
            "\n",
            "name\n",
            "['What is your name', 'what should I call you?', 'what is your name', 'who are you', 'can you tell me your name']\n",
            "['You can call me Neural!', \"I'm neural\", \"I'm Neural, The assistant\"]\n",
            "\n",
            "shop\n",
            "[\"I'd like to buy something\", 'What are your products?', 'what do you recommend?', 'What are you selling?']\n",
            "['We sell books! Lots of them.']\n",
            "\n",
            "hours\n",
            "['When are you guys open?', 'What are your hours', 'hours of operation', 'price', 'value', 'mrp']\n",
            "['24/7']\n",
            "\n",
            "crop\n",
            "['What is the price of maize', 'How much is Wheat worth', 'selling price of rice']\n",
            "['[Unavailable]']\n",
            "\n",
            "stocks\n",
            "['what stocks do I own?', 'how are my shares?', 'what companies am I invested in?', 'What am I doing in stocks']\n",
            "['You own the following shares: ABBV, APPL, FB, NVDA and an ETF of the S&P 500 Index!']\n",
            "\n",
            "name\n"
          ]
        }
      ],
      "source": [
        "for i in intents:\n",
        "    for j in i.keys():\n",
        "        print(i[j])\n",
        "    print()\n",
        "\n",
        "intents = {\"intents\": intents}\n",
        "print(intents['intents'][3]['tag'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc7pO9YveUr0"
      },
      "source": [
        "### *loading our intents*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "sfmfSoL_ft1_",
        "outputId": "2eb8e2ed-1600-4ca1-b365-abe30879f43c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-809b8a5c-4074-4dfe-9941-c6af92cafad2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-809b8a5c-4074-4dfe-9941-c6af92cafad2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving intents_eng.json to intents_eng (3).json\n"
          ]
        }
      ],
      "source": [
        "# loading file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6ubJY5ZuDg9",
        "outputId": "c567c364-7590-4042-f11b-0c30e2997fb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'intents_eng.json': b'{\\r\\n    \"intents\": [\\r\\n        {\\r\\n            \"tag\": \"greetings\",\\r\\n            \"pattern\": [\"hello\", \"hey\", \"hi\", \"good day\", \"good morning\"],\\r\\n            \"responses\": [\"Hello\", \"What can I do for you?\"]\\r\\n        },  \\r\\n        {\\r\\n            \"tag\": \"goodbye\",\\r\\n            \"pattern\": [\"cya\", \"see you later\", \"I\\'m leaving\", \"goodbye\", \"have a good day\", \"I am leaving\", \"bye\", \"see ya\"],\\r\\n            \"responses\": [\"Goodbye\", \"Nice to have met you\"]\\r\\n        },  \\r\\n        {\\r\\n            \"tag\": \"age\",\\r\\n            \"pattern\": [\"how old\", \"how old is florian\", \"what is your age\", \"how old are you?\", \"age?\"],\\r\\n            \"responses\": [\"My owner florian is 21 years old!\", \"21 years!\", \"21\"]\\r\\n        },  \\r\\n        {\\r\\n            \"tag\": \"name\",\\r\\n            \"pattern\": [\"What is your name\", \"what should I call you?\", \"what is your name\", \"who are you\", \"can you tell me your name\"],\\r\\n            \"responses\": [\"You can call me Neural!\", \"I\\'m neural\", \"I\\'m Neural, The assistant to Florian\"]\\r\\n        },  \\r\\n        {\\r\\n            \"tag\": \"shop\",\\r\\n            \"pattern\": [\"I\\'d like to buy something\", \"What are your products?\", \"what do you recommend?\", \"What are you selling?\"],\\r\\n            \"responses\": [\"We sell books! Lots of them.\"]\\r\\n        },  \\r\\n        {\\r\\n            \"tag\": \"hours\",\\r\\n            \"pattern\": [\"When are you guys open?\", \"What are your hours\", \"hours of operation\", \"price\", \"value\", \"mrp\"],\\r\\n            \"responses\": [\"24/7\"]\\r\\n        },  \\r\\n        {\\r\\n            \"tag\": \"crop\",\\r\\n            \"pattern\": [\"What is the price of maize\", \"How much is Wheat worth\", \"selling price of rice\"],\\r\\n            \"responses\": [\"[Unavailable]\"]\\r\\n        },  \\r\\n        {\\r\\n            \"tag\": \"stocks\",\\r\\n            \"pattern\": [\"what stocks do I own?\", \"how are my shares?\", \"what companies am I invested in?\", \"What am I doing in stocks\"],\\r\\n            \"responses\": [\"You own the following shares: ABBV, APPL, FB, NVDA and an ETF of the S&P 500 Index!\"]\\r\\n        }\\r\\n    ]\\r\\n}'}\n"
          ]
        }
      ],
      "source": [
        "print(uploaded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDK6xegZf-xZ",
        "outputId": "230ced2f-486e-452d-9a6d-152ba224a49b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "name\n"
          ]
        }
      ],
      "source": [
        "intents =  json.loads(uploaded['intents_eng.json'])\n",
        "print(intents['intents'][3]['tag'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0v9OXc9glF_"
      },
      "source": [
        "### *Creating intermediate Data*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "p_PC6Qp1iFx9"
      },
      "outputs": [],
      "source": [
        "# creatig useful lists\n",
        "words = []\n",
        "classes = []\n",
        "docs = []\n",
        "\n",
        "ignore_letters = [\"!\", \".\", \",\", \"?\"]\n",
        "\n",
        "# iterating over intents\n",
        "for intent in intents['intents']:\n",
        "  for pat in intent['pattern']:\n",
        "    # tokenizing and adding tokens to the word list\n",
        "    word_list = nltk.word_tokenize(pat)\n",
        "    if word_list is not None:\n",
        "      words.extend(word_list)\n",
        "\n",
        "      # appending \n",
        "      docs.append((word_list, intent['tag']))\n",
        "\n",
        "      if intent['tag'] not in classes:\n",
        "        classes.append(intent['tag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmBoCi8RlSKS",
        "outputId": "07f0635a-f5d9-4459-b28d-9b0c3774fae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['hello', 'hey', 'hi', 'good', 'day', 'good', 'morning', 'cya', 'see', 'you', 'later', 'I', \"'m\", 'leaving', 'goodbye', 'have', 'a', 'good', 'day', 'I', 'am', 'leaving', 'bye', 'see', 'ya', 'how', 'old', 'how', 'old', 'is', 'florian', 'what', 'is', 'your', 'age', 'how', 'old', 'are', 'you', '?', 'age', '?', 'What', 'is', 'your', 'name', 'what', 'should', 'I', 'call', 'you', '?', 'what', 'is', 'your', 'name', 'who', 'are', 'you', 'can', 'you', 'tell', 'me', 'your', 'name', 'I', \"'d\", 'like', 'to', 'buy', 'something', 'What', 'are', 'your', 'products', '?', 'what', 'do', 'you', 'recommend', '?', 'What', 'are', 'you', 'selling', '?', 'When', 'are', 'you', 'guys', 'open', '?', 'What', 'are', 'your', 'hours', 'hours', 'of', 'operation', 'price', 'value', 'mrp', 'What', 'is', 'the', 'price', 'of', 'maize', 'How', 'much', 'is', 'Wheat', 'worth', 'selling', 'price', 'of', 'rice', 'what', 'stocks', 'do', 'I', 'own', '?', 'how', 'are', 'my', 'shares', '?', 'what', 'companies', 'am', 'I', 'invested', 'in', '?', 'What', 'am', 'I', 'doing', 'in', 'stocks']\n"
          ]
        }
      ],
      "source": [
        "print(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfU_Nf1Rgtnv"
      },
      "source": [
        "### *Lemmatizing*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "koTC32Dkl9jh"
      },
      "outputs": [
        {
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Angad Sandhu/nltk_data'\n    - 'c:\\\\Users\\\\Angad Sandhu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\nltk_data'\n    - 'c:\\\\Users\\\\Angad Sandhu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Angad Sandhu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Angad Sandhu\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\Angad Sandhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=82'>83</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=83'>84</a>\u001b[0m     root \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mfind(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubdir\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mzip_name\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=84'>85</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\Angad Sandhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/data.py?line=581'>582</a>\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/data.py?line=582'>583</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n",
            "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4.zip/omw-1.4/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Angad Sandhu/nltk_data'\n    - 'c:\\\\Users\\\\Angad Sandhu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\nltk_data'\n    - 'c:\\\\Users\\\\Angad Sandhu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Angad Sandhu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Angad Sandhu\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32md:\\Code\\Research\\ChatBot\\English\\ai_chatbot.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/Research/ChatBot/English/ai_chatbot.ipynb#ch0000012?line=0'>1</a>\u001b[0m \u001b[39m# lemmatizing our words\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/Research/ChatBot/English/ai_chatbot.ipynb#ch0000012?line=1'>2</a>\u001b[0m lemmatizer \u001b[39m=\u001b[39m WordNetLemmatizer()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Code/Research/ChatBot/English/ai_chatbot.ipynb#ch0000012?line=3'>4</a>\u001b[0m words \u001b[39m=\u001b[39m [lemmatizer\u001b[39m.\u001b[39mlemmatize(word) \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m words \u001b[39mif\u001b[39;00m word \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ignore_letters]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/Research/ChatBot/English/ai_chatbot.ipynb#ch0000012?line=5'>6</a>\u001b[0m \u001b[39m# removing duplicates\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/Research/ChatBot/English/ai_chatbot.ipynb#ch0000012?line=6'>7</a>\u001b[0m words \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mset\u001b[39m(words))\n",
            "\u001b[1;32md:\\Code\\Research\\ChatBot\\English\\ai_chatbot.ipynb Cell 17'\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/Research/ChatBot/English/ai_chatbot.ipynb#ch0000012?line=0'>1</a>\u001b[0m \u001b[39m# lemmatizing our words\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/Research/ChatBot/English/ai_chatbot.ipynb#ch0000012?line=1'>2</a>\u001b[0m lemmatizer \u001b[39m=\u001b[39m WordNetLemmatizer()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Code/Research/ChatBot/English/ai_chatbot.ipynb#ch0000012?line=3'>4</a>\u001b[0m words \u001b[39m=\u001b[39m [lemmatizer\u001b[39m.\u001b[39;49mlemmatize(word) \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m words \u001b[39mif\u001b[39;00m word \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ignore_letters]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/Research/ChatBot/English/ai_chatbot.ipynb#ch0000012?line=5'>6</a>\u001b[0m \u001b[39m# removing duplicates\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/Research/ChatBot/English/ai_chatbot.ipynb#ch0000012?line=6'>7</a>\u001b[0m words \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mset\u001b[39m(words))\n",
            "File \u001b[1;32mc:\\Users\\Angad Sandhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\stem\\wordnet.py:45\u001b[0m, in \u001b[0;36mWordNetLemmatizer.lemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/stem/wordnet.py?line=32'>33</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlemmatize\u001b[39m(\u001b[39mself\u001b[39m, word: \u001b[39mstr\u001b[39m, pos: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mn\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/stem/wordnet.py?line=33'>34</a>\u001b[0m     \u001b[39m\"\"\"Lemmatize `word` using WordNet's built-in morphy function.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/stem/wordnet.py?line=34'>35</a>\u001b[0m \u001b[39m    Returns the input word unchanged if it cannot be found in WordNet.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/stem/wordnet.py?line=35'>36</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/stem/wordnet.py?line=42'>43</a>\u001b[0m \u001b[39m    :return: The lemma of `word`, for the given `pos`.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/stem/wordnet.py?line=43'>44</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/stem/wordnet.py?line=44'>45</a>\u001b[0m     lemmas \u001b[39m=\u001b[39m wn\u001b[39m.\u001b[39;49m_morphy(word, pos)\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/stem/wordnet.py?line=45'>46</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmin\u001b[39m(lemmas, key\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m) \u001b[39mif\u001b[39;00m lemmas \u001b[39melse\u001b[39;00m word\n",
            "File \u001b[1;32mc:\\Users\\Angad Sandhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=117'>118</a>\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__bases__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=118'>119</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLazyCorpusLoader object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m__bases__\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=120'>121</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__load()\n\u001b[0;32m    <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=121'>122</a>\u001b[0m \u001b[39m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=122'>123</a>\u001b[0m \u001b[39m# __class__ to something new:\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=123'>124</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, attr)\n",
            "File \u001b[1;32mc:\\Users\\Angad Sandhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py:89\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=85'>86</a>\u001b[0m             \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=87'>88</a>\u001b[0m \u001b[39m# Load the corpus.\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=88'>89</a>\u001b[0m corpus \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__reader_cls(root, \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__kwargs)\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=90'>91</a>\u001b[0m \u001b[39m# This is where the magic happens!  Transform ourselves into\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=91'>92</a>\u001b[0m \u001b[39m# the corpus by modifying our own __dict__ and __class__ to\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=92'>93</a>\u001b[0m \u001b[39m# match that of the corpus.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=94'>95</a>\u001b[0m args, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__kwargs\n",
            "File \u001b[1;32mc:\\Users\\Angad Sandhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py:1176\u001b[0m, in \u001b[0;36mWordNetCorpusReader.__init__\u001b[1;34m(self, root, omw_reader)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1171'>1172</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1172'>1173</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe multilingual functions are not available with this Wordnet version\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1173'>1174</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1174'>1175</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1175'>1176</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprovenances \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49momw_prov()\n\u001b[0;32m   <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1177'>1178</a>\u001b[0m \u001b[39m# A cache to store the wordnet data of multiple languages\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1178'>1179</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lang_data \u001b[39m=\u001b[39m defaultdict(\u001b[39mlist\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\Angad Sandhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py:1285\u001b[0m, in \u001b[0;36mWordNetCorpusReader.omw_prov\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1282'>1283</a>\u001b[0m provdict \u001b[39m=\u001b[39m {}\n\u001b[0;32m   <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1283'>1284</a>\u001b[0m provdict[\u001b[39m\"\u001b[39m\u001b[39meng\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1284'>1285</a>\u001b[0m fileids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_omw_reader\u001b[39m.\u001b[39;49mfileids()\n\u001b[0;32m   <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1285'>1286</a>\u001b[0m \u001b[39mfor\u001b[39;00m fileid \u001b[39min\u001b[39;00m fileids:\n\u001b[0;32m   <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/reader/wordnet.py?line=1286'>1287</a>\u001b[0m     prov, langfile \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplit(fileid)\n",
            "File \u001b[1;32mc:\\Users\\Angad Sandhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=117'>118</a>\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__bases__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=118'>119</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLazyCorpusLoader object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m__bases__\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=120'>121</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__load()\n\u001b[0;32m    <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=121'>122</a>\u001b[0m \u001b[39m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=122'>123</a>\u001b[0m \u001b[39m# __class__ to something new:\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=123'>124</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, attr)\n",
            "File \u001b[1;32mc:\\Users\\Angad Sandhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=83'>84</a>\u001b[0m             root \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfind(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubdir\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mzip_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=84'>85</a>\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=85'>86</a>\u001b[0m             \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=87'>88</a>\u001b[0m \u001b[39m# Load the corpus.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=88'>89</a>\u001b[0m corpus \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__reader_cls(root, \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__kwargs)\n",
            "File \u001b[1;32mc:\\Users\\Angad Sandhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=78'>79</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=79'>80</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=80'>81</a>\u001b[0m         root \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mfind(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubdir\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__name\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=81'>82</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/corpus/util.py?line=82'>83</a>\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\Angad Sandhu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/data.py?line=580'>581</a>\u001b[0m sep \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m70\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/data.py?line=581'>582</a>\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Angad%20Sandhu/AppData/Local/Programs/Python/Python39/lib/site-packages/nltk/data.py?line=582'>583</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n",
            "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Angad Sandhu/nltk_data'\n    - 'c:\\\\Users\\\\Angad Sandhu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\nltk_data'\n    - 'c:\\\\Users\\\\Angad Sandhu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Angad Sandhu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Angad Sandhu\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "# lemmatizing our words\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "  \n",
        "words = [lemmatizer.lemmatize(word) for word in words if word not in ignore_letters]\n",
        "\n",
        "# removing duplicates\n",
        "words = sorted(set(words))\n",
        "classes = sorted(set(classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2cMhyPNmXkX",
        "outputId": "1fcc97ac-d4c4-4b25-833a-20a6f7537010"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"'d\", \"'m\", 'How', 'I', 'What', 'Wheat', 'When', 'a', 'age', 'am', 'are', 'buy', 'bye', 'call', 'can', 'company', 'cya', 'day', 'do', 'doing', 'florian', 'good', 'goodbye', 'guy', 'have', 'hello', 'hey', 'hi', 'hour', 'how', 'in', 'invested', 'is', 'later', 'leaving', 'like', 'maize', 'me', 'morning', 'mrp', 'much', 'my', 'name', 'of', 'old', 'open', 'operation', 'own', 'price', 'product', 'recommend', 'rice', 'see', 'selling', 'share', 'should', 'something', 'stock', 'tell', 'the', 'to', 'value', 'what', 'who', 'worth', 'ya', 'you', 'your']\n"
          ]
        }
      ],
      "source": [
        "print(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS93Rg6Mgw_O"
      },
      "source": [
        "### *Saving Data*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "GX01aKlRsDOe"
      },
      "outputs": [],
      "source": [
        "# adding all info to file\n",
        "pickle.dump(words, open(\"words.pkl\", 'wb'))\n",
        "pickle.dump(classes, open(\"classes.pkl\", 'wb'))\n",
        "pickle.dump(docs, open(\"docs.pkl\", 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tEPYG3Cg4aE"
      },
      "source": [
        "### *Creattig Training Data*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "8sYNbCXes2QE"
      },
      "outputs": [],
      "source": [
        "# representing words as numeric data using bag of words\n",
        "# so that we could use this in a neural network\n",
        "training = []\n",
        "output_empty = [0]*len(classes)\n",
        "\n",
        "for doc in docs:\n",
        "  bag = []\n",
        "  word_patterns = doc[0]\n",
        "  word_patterns = [lemmatizer.lemmatize(word) for word in word_patterns]\n",
        "\n",
        "  for word in words:\n",
        "    bag.append(1) if word in word_patterns else bag.append(0)\n",
        "\n",
        "  # print(output_row)\n",
        "  output_row = list(output_empty)\n",
        "  output_row[classes.index(doc[1])] = 1\n",
        "  training.append([bag, output_row])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGp2hqp_g1EC"
      },
      "source": [
        "### *Pre-Processing*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be6ugTvGvqBP",
        "outputId": "75aacb3e-8c82-48d2-b98c-8ba288c8a55b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(40, 2)\n",
            "(40, 8)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ],
      "source": [
        "# shufling our data\n",
        "random.shuffle(training)\n",
        "training = np.array(training)\n",
        "\n",
        "print(training.shape)\n",
        "\n",
        "\n",
        "# spliting to X and y values\n",
        "train_x = np.array(list(training[:, 0]))\n",
        "train_y = np.array(list(training[:, 1]))\n",
        "\n",
        "# print(np.asarray(train_x))\n",
        "print(train_y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaG15lsSwVtn"
      },
      "source": [
        "### *Building Neural Net*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "KsK3PX-uwU3M"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(len(train_x[0]), ), activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_y[0]), activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw0qK1jecsg3",
        "outputId": "07864dac-3899-4716-aa94-63c901c21240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 128)               8832      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 8)                 520       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,608\n",
            "Trainable params: 17,608\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.09, nesterov=True)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rakIHScUcsXd",
        "outputId": "4f471665-2721-4927-8068-622841e94c0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.1196 - accuracy: 0.1500\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0960 - accuracy: 0.1000\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.1099 - accuracy: 0.1250\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0401 - accuracy: 0.0750\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0867 - accuracy: 0.1750\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.1345 - accuracy: 0.1750\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0757 - accuracy: 0.1500\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0303 - accuracy: 0.1750\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0009 - accuracy: 0.1250\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0028 - accuracy: 0.1500\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0314 - accuracy: 0.2000\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0103 - accuracy: 0.1500\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.9990 - accuracy: 0.2500\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0110 - accuracy: 0.1500\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0220 - accuracy: 0.2750\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0149 - accuracy: 0.2250\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.9939 - accuracy: 0.3000\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.9621 - accuracy: 0.2750\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0024 - accuracy: 0.2000\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.9684 - accuracy: 0.2250\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.9498 - accuracy: 0.2750\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.9463 - accuracy: 0.2750\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.9304 - accuracy: 0.3750\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.9613 - accuracy: 0.2500\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.9263 - accuracy: 0.3250\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.9152 - accuracy: 0.3250\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8945 - accuracy: 0.4750\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8661 - accuracy: 0.3250\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8678 - accuracy: 0.3500\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8212 - accuracy: 0.3000\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8284 - accuracy: 0.3500\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8606 - accuracy: 0.3500\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8938 - accuracy: 0.2500\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8718 - accuracy: 0.3500\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8396 - accuracy: 0.3250\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8363 - accuracy: 0.3750\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8591 - accuracy: 0.4750\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7947 - accuracy: 0.4000\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8353 - accuracy: 0.3750\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8560 - accuracy: 0.2250\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7746 - accuracy: 0.3500\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7788 - accuracy: 0.3250\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.6851 - accuracy: 0.4750\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8420 - accuracy: 0.3500\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7200 - accuracy: 0.4250\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7290 - accuracy: 0.5000\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7281 - accuracy: 0.4750\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7121 - accuracy: 0.4500\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.6859 - accuracy: 0.4750\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7505 - accuracy: 0.4250\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6907 - accuracy: 0.5250\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.5697 - accuracy: 0.5500\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7234 - accuracy: 0.5000\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.6193 - accuracy: 0.5000\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.6601 - accuracy: 0.3750\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.6681 - accuracy: 0.5000\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.6625 - accuracy: 0.4500\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.5702 - accuracy: 0.5500\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.5297 - accuracy: 0.6000\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.4913 - accuracy: 0.5750\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.5974 - accuracy: 0.4000\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.6620 - accuracy: 0.4250\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.6136 - accuracy: 0.5250\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.5104 - accuracy: 0.6000\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.5355 - accuracy: 0.5750\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.5259 - accuracy: 0.5500\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.5314 - accuracy: 0.5500\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.5137 - accuracy: 0.5250\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.4939 - accuracy: 0.5250\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.4650 - accuracy: 0.6750\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.3963 - accuracy: 0.6500\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3749 - accuracy: 0.5750\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.3149 - accuracy: 0.7000\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.3982 - accuracy: 0.5250\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.4026 - accuracy: 0.6000\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.3421 - accuracy: 0.7000\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.5147 - accuracy: 0.6000\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.3598 - accuracy: 0.6250\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.3915 - accuracy: 0.6250\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.2958 - accuracy: 0.5750\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.2643 - accuracy: 0.7000\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2021 - accuracy: 0.7500\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.3340 - accuracy: 0.6000\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2894 - accuracy: 0.6000\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1682 - accuracy: 0.7000\n",
            "Epoch 86/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.2344 - accuracy: 0.6750\n",
            "Epoch 87/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.2679 - accuracy: 0.6000\n",
            "Epoch 88/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.3564 - accuracy: 0.5500\n",
            "Epoch 89/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1875 - accuracy: 0.6750\n",
            "Epoch 90/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1819 - accuracy: 0.7250\n",
            "Epoch 91/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.3291 - accuracy: 0.6250\n",
            "Epoch 92/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1805 - accuracy: 0.6500\n",
            "Epoch 93/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1674 - accuracy: 0.7000\n",
            "Epoch 94/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1931 - accuracy: 0.6250\n",
            "Epoch 95/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.2347 - accuracy: 0.6750\n",
            "Epoch 96/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1302 - accuracy: 0.7500\n",
            "Epoch 97/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9674 - accuracy: 0.7750\n",
            "Epoch 98/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.2064 - accuracy: 0.6250\n",
            "Epoch 99/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1241 - accuracy: 0.8000\n",
            "Epoch 100/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1287 - accuracy: 0.7250\n",
            "Epoch 101/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9485 - accuracy: 0.7250\n",
            "Epoch 102/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1423 - accuracy: 0.6500\n",
            "Epoch 103/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0157 - accuracy: 0.7250\n",
            "Epoch 104/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0847 - accuracy: 0.7500\n",
            "Epoch 105/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1316 - accuracy: 0.6500\n",
            "Epoch 106/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9838 - accuracy: 0.8250\n",
            "Epoch 107/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9239 - accuracy: 0.7000\n",
            "Epoch 108/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0460 - accuracy: 0.7250\n",
            "Epoch 109/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9808 - accuracy: 0.7750\n",
            "Epoch 110/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9801 - accuracy: 0.7000\n",
            "Epoch 111/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9455 - accuracy: 0.7500\n",
            "Epoch 112/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9294 - accuracy: 0.8000\n",
            "Epoch 113/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9925 - accuracy: 0.6750\n",
            "Epoch 114/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8769 - accuracy: 0.8000\n",
            "Epoch 115/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0118 - accuracy: 0.8000\n",
            "Epoch 116/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9981 - accuracy: 0.7500\n",
            "Epoch 117/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9073 - accuracy: 0.7000\n",
            "Epoch 118/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8220 - accuracy: 0.7750\n",
            "Epoch 119/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8236 - accuracy: 0.7250\n",
            "Epoch 120/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8086 - accuracy: 0.8750\n",
            "Epoch 121/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8159 - accuracy: 0.8000\n",
            "Epoch 122/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8653 - accuracy: 0.7750\n",
            "Epoch 123/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0565 - accuracy: 0.7000\n",
            "Epoch 124/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7767 - accuracy: 0.8500\n",
            "Epoch 125/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7992 - accuracy: 0.8250\n",
            "Epoch 126/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8147 - accuracy: 0.8250\n",
            "Epoch 127/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8571 - accuracy: 0.8250\n",
            "Epoch 128/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.8750\n",
            "Epoch 129/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7782 - accuracy: 0.8250\n",
            "Epoch 130/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8220 - accuracy: 0.7250\n",
            "Epoch 131/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8167 - accuracy: 0.8000\n",
            "Epoch 132/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7232 - accuracy: 0.8500\n",
            "Epoch 133/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.9000\n",
            "Epoch 134/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7638 - accuracy: 0.8000\n",
            "Epoch 135/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8342 - accuracy: 0.7500\n",
            "Epoch 136/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.8500\n",
            "Epoch 137/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.8500\n",
            "Epoch 138/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8611 - accuracy: 0.8000\n",
            "Epoch 139/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.8000\n",
            "Epoch 140/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.8500\n",
            "Epoch 141/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.8500\n",
            "Epoch 142/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7813 - accuracy: 0.7750\n",
            "Epoch 143/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6734 - accuracy: 0.8500\n",
            "Epoch 144/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6747 - accuracy: 0.8000\n",
            "Epoch 145/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6578 - accuracy: 0.8750\n",
            "Epoch 146/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7464 - accuracy: 0.8750\n",
            "Epoch 147/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.8000\n",
            "Epoch 148/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.8500\n",
            "Epoch 149/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7391 - accuracy: 0.8750\n",
            "Epoch 150/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7057 - accuracy: 0.8000\n",
            "Epoch 151/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7176 - accuracy: 0.8750\n",
            "Epoch 152/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.9000\n",
            "Epoch 153/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7090 - accuracy: 0.8000\n",
            "Epoch 154/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5926 - accuracy: 0.8750\n",
            "Epoch 155/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7453 - accuracy: 0.7000\n",
            "Epoch 156/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.8500\n",
            "Epoch 157/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.8000\n",
            "Epoch 158/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6497 - accuracy: 0.8750\n",
            "Epoch 159/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.8250\n",
            "Epoch 160/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7176 - accuracy: 0.8250\n",
            "Epoch 161/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.8750\n",
            "Epoch 162/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7436 - accuracy: 0.7000\n",
            "Epoch 163/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.9250\n",
            "Epoch 164/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.8250\n",
            "Epoch 165/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.8500\n",
            "Epoch 166/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7405 - accuracy: 0.8000\n",
            "Epoch 167/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.8750\n",
            "Epoch 168/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.9000\n",
            "Epoch 169/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.9250\n",
            "Epoch 170/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.8250\n",
            "Epoch 171/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.9000\n",
            "Epoch 172/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.8750\n",
            "Epoch 173/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.9250\n",
            "Epoch 174/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.9250\n",
            "Epoch 175/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.9250\n",
            "Epoch 176/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.9500\n",
            "Epoch 177/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.9000\n",
            "Epoch 178/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.9250\n",
            "Epoch 179/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.8750\n",
            "Epoch 180/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.8250\n",
            "Epoch 181/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.9000\n",
            "Epoch 182/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.8750\n",
            "Epoch 183/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.8750\n",
            "Epoch 184/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.8750\n",
            "Epoch 185/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.9000\n",
            "Epoch 186/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.9250\n",
            "Epoch 187/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8750\n",
            "Epoch 188/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.8250\n",
            "Epoch 189/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.9750\n",
            "Epoch 190/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.8750\n",
            "Epoch 191/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.9000\n",
            "Epoch 192/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.9250\n",
            "Epoch 193/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.9250\n",
            "Epoch 194/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.9000\n",
            "Epoch 195/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.9250\n",
            "Epoch 196/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.9000\n",
            "Epoch 197/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.9250\n",
            "Epoch 198/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.8750\n",
            "Epoch 199/200\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8750\n",
            "Epoch 200/200\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.9250\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_x, train_y, epochs=200, batch_size=4, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "06k1fb2yWF1A"
      },
      "outputs": [],
      "source": [
        "model.save(\"ai_chatbot.h5\", history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_MYpfoVbN3w"
      },
      "source": [
        "## EXECUTING CHATBOT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFYgxrMLd7QZ",
        "outputId": "dfdab382-ff1a-4b01-f610-d2a0ea83ec1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "import random\n",
        "import json\n",
        "import pickle   # for serialization\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# lemmatizing our words\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1PcFlnAek4b"
      },
      "source": [
        "### *Loading Our Intents*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "Sk1Xnoz_eQvZ",
        "outputId": "967f6bcd-44c2-42a7-8898-1a5f9d27abb9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1f010ab7-b81e-4b78-ad8f-a7553d455c9a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1f010ab7-b81e-4b78-ad8f-a7553d455c9a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving intents_eng.json to intents_eng (4).json\n"
          ]
        }
      ],
      "source": [
        "# loading file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YOfY0qbubxA",
        "outputId": "3cdc9972-4caf-448d-f3df-7dcd84e7ab5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'intents_eng.json': b'{\\r\\n    \"intents\": [\\r\\n        {\\r\\n            \"tag\": \"greetings\",\\r\\n            \"pattern\": [\"hello\", \"hey\", \"hi\", \"good day\", \"good morning\"],\\r\\n            \"responses\": [\"Hello\", \"What can I do for you?\"]\\r\\n        },  \\r\\n        {\\r\\n            \"tag\": \"goodbye\",\\r\\n            \"pattern\": [\"cya\", \"see you later\", \"I\\'m leaving\", \"goodbye\", \"have a good day\", \"I am leaving\", \"bye\", \"see ya\"],\\r\\n            \"responses\": [\"Goodbye\", \"Nice to have met you\"]\\r\\n        },  \\r\\n        {\\r\\n            \"tag\": \"age\",\\r\\n            \"pattern\": [\"how old\", \"how old is florian\", \"what is your age\", \"how old are you?\", \"age?\"],\\r\\n            \"responses\": [\"My owner florian is 21 years old!\", \"21 years!\", \"21\"]\\r\\n        },  \\r\\n        {\\r\\n            \"tag\": \"name\",\\r\\n            \"pattern\": [\"What is your name\", \"what should I call you?\", \"what is your name\", \"who are you\", \"can you tell me your name\"],\\r\\n            \"responses\": [\"You can call me Neural!\", \"I\\'m neural\", \"I\\'m Neural, The assistant to Florian\"]\\r\\n        },  \\r\\n        {\\r\\n            \"tag\": \"shop\",\\r\\n            \"pattern\": [\"I\\'d like to buy something\", \"What are your products?\", \"what do you recommend?\", \"What are you selling?\"],\\r\\n            \"responses\": [\"We sell books! Lots of them.\"]\\r\\n        },  \\r\\n        {\\r\\n            \"tag\": \"hours\",\\r\\n            \"pattern\": [\"When are you guys open?\", \"What are your hours\", \"hours of operation\", \"price\", \"value\", \"mrp\"],\\r\\n            \"responses\": [\"24/7\"]\\r\\n        },  \\r\\n        {\\r\\n            \"tag\": \"crop\",\\r\\n            \"pattern\": [\"What is the price of maize\", \"How much is Wheat worth\", \"selling price of rice\"],\\r\\n            \"responses\": [\"[Unavailable]\"]\\r\\n        },  \\r\\n        {\\r\\n            \"tag\": \"stocks\",\\r\\n            \"pattern\": [\"what stocks do I own?\", \"how are my shares?\", \"what companies am I invested in?\", \"What am I doing in stocks\"],\\r\\n            \"responses\": [\"You own the following shares: ABBV, APPL, FB, NVDA and an ETF of the S&P 500 Index!\"]\\r\\n        }\\r\\n    ]\\r\\n}'}\n"
          ]
        }
      ],
      "source": [
        "print(uploaded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIlmoE03eR6i",
        "outputId": "c4fd8eab-7382-4d94-b6be-05efac836f3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "age\n"
          ]
        }
      ],
      "source": [
        "intents =  json.loads(uploaded['intents_eng.json'])\n",
        "print(intents['intents'][2]['tag'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrDV4PZegIVG"
      },
      "source": [
        "### *Loading up our saved files*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Kl3_5tiegMCp"
      },
      "outputs": [],
      "source": [
        "words = pickle.load(open('words.pkl', 'rb'))\n",
        "classes = pickle.load(open('classes.pkl', 'rb'))\n",
        "docs = pickle.load(open('docs.pkl', 'rb'))\n",
        "\n",
        "model = load_model(\"ai_chatbot.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9t9G_Ni7Nyq"
      },
      "source": [
        "### *Creating Crop Data Data Structure by Querying dataset*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load crop data\n",
        "uploaded = files.upload()\n",
        "crop_data =  json.loads(uploaded['crop_data_eng.json'])\n",
        "print(intents['intents'][3]['tag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "5k0IqnsZxBtV"
      },
      "outputs": [],
      "source": [
        "# Getting Crop Data\n",
        "crop_data = {\n",
        "    'rice': 10,\n",
        "    'wheat': 20,\n",
        "    'maize': 30\n",
        "}\n",
        "\n",
        "crop_names = list(crop_data.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaAZ3JOlhgsw"
      },
      "source": [
        "### *Creating Helper Functions*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "5S7DM3XQhki2"
      },
      "outputs": [],
      "source": [
        "def clean_sentence(sentence):\n",
        "  sentence_words = nltk.word_tokenize(sentence)\n",
        "  sentence_words = [lemmatizer.lemmatize(word) for word in sentence_words]\n",
        "  return sentence_words\n",
        "\n",
        "def bag_of_words(sentence):\n",
        "  sentence_words = clean_sentence(sentence)\n",
        "  bag = [0] * len(words)\n",
        "\n",
        "  for w in sentence_words:\n",
        "    for i, word in enumerate(words):\n",
        "      if word == w:\n",
        "        bag[i] = 1\n",
        "  \n",
        "  return np.array(bag)\n",
        "\n",
        "def predict_class(sentence):\n",
        "  ERROR_THRESHOLD = 0.25\n",
        "\n",
        "  bow = bag_of_words(sentence)\n",
        "  res = model.predict(np.array([bow]))[0]\n",
        "\n",
        "  results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
        "\n",
        "  results.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  return_list = []\n",
        "  for r in results:\n",
        "    return_list.append({ 'intent': classes[r[0]], 'probability': str(r[1]) })\n",
        "\n",
        "  return return_list\n",
        "\n",
        "def get_response(intents_list, intents_json):\n",
        "  tag = intents_list[0]['intent']\n",
        "  list_of_intents = intents_json['intents']\n",
        "  for i in list_of_intents:\n",
        "    if i['tag'] == tag:\n",
        "      result = random.choice(i['responses'])\n",
        "      break\n",
        "  return result\n",
        "\n",
        "def get_crop_data(msg):\n",
        "  bow = list(msg.split())\n",
        "  bow = [string.lower() for string in bow]\n",
        "  print(\"message words : \", bow)\n",
        "  print(\"crops : \", crop_names)\n",
        "\n",
        "  common_crops = list(set(bow) & set(crop_names))\n",
        "  print(\"common crops : \", common_crops)\n",
        "\n",
        "  if not common_crops:\n",
        "    return \"No Crop Data Found, Please Try again\"\n",
        "  else:\n",
        "    crop_res = \"The price of {} is {}\".format(common_crops[0], crop_data[common_crops[0]])\n",
        "    return crop_res\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7lzzpChriSB"
      },
      "source": [
        "## Running BOT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "WnYIf2NkrkSG"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "  message = input('Input Message : ')\n",
        "  ints = predict_class(message)\n",
        "  print(ints)\n",
        "\n",
        "  if ints[0]['intent'] == 'crop':\n",
        "    res = get_crop_data(message)\n",
        "  else:\n",
        "    res = get_response(ints, intents)\n",
        "\n",
        "  print(res)\n",
        "  print(\"Output Message : \", res, \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ai_chatbot.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "f7b54faf5a5435677ab8295a95df66fdf7851ad2c8bf06d055bbbcd678fd2480"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
