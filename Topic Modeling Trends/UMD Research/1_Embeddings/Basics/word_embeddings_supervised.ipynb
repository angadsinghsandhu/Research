{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers as tf_layer\n",
    "\n",
    "from tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \"nice food\",\n",
    "    \"amazing restaurant\",\n",
    "    \"too good\",\n",
    "    \"horrible sevice\",\n",
    "    \"highly disgusting\",\n",
    "    \"never recommending this to anyone\",\n",
    "]\n",
    "\n",
    "sentiment = np.array([1, 1, 1, 0, 0, 0,]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying vocabulary and padding dimention\n",
    "vocab_size = 500\n",
    "pad_len = 5\n",
    "\n",
    "# encoding reviews into one-hot vectors\n",
    "encoded_reviews = [one_hot(i, vocab_size) for i in reviews]\n",
    "\n",
    "# padding sentences\n",
    "padded_reviews = pad_sequences(encoded_reviews, maxlen=pad_len, padding='post')\n",
    "\n",
    "# specifying the size of our vector embeddings \n",
    "vector_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[184, 263,   0,   0,   0],\n",
       "       [407, 327,   0,   0,   0],\n",
       "       [251, 471,   0,   0,   0],\n",
       "       [403,  34,   0,   0,   0],\n",
       "       [212, 491,   0,   0,   0],\n",
       "       [ 54, 152, 184, 174,  65]], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining NLP model\n",
    "model = Sequential()\n",
    "\n",
    "# specifyng model layers\n",
    "model.add(k.layers.Embedding(vocab_size, vector_size, input_length=pad_len, name=\"embedding\"))\n",
    "model.add(k.layers.Flatten())\n",
    "model.add(k.layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = padded_reviews\n",
    "y = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 5, 5)              2500      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 2,526\n",
      "Trainable params: 2,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.7028 - accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7012 - accuracy: 0.3333\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6996 - accuracy: 0.3333\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.3333\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.3333\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.3333\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.3333\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.6667\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.8333\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.8333\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.8333\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.8333\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6790 - accuracy: 0.8333\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.8333\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6759 - accuracy: 0.8333\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.8333\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.8333\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6712 - accuracy: 0.8333\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6696 - accuracy: 0.8333\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6680 - accuracy: 0.8333\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6664 - accuracy: 0.8333\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6649 - accuracy: 0.8333\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6633 - accuracy: 0.8333\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.8333\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.8333\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.8333\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6568 - accuracy: 0.8333\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6551 - accuracy: 0.8333\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.8333\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.8333\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.8333\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.8333\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.8333\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6450 - accuracy: 0.8333\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.8333\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6415 - accuracy: 0.8333\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6398 - accuracy: 0.8333\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6380 - accuracy: 0.8333\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.8333\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6344 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6326 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6308 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1de5845b10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running our model\n",
    "model.fit(x, y, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 121ms/step - loss: 0.6195 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating the model\n",
    "loss, accuracy = model.evaluate(x, y)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the weights of our embedding layer i.e. the word embeddings\n",
    "weights = model.get_layer('embedding').get_weights()[0]\n",
    "len(weights)\n",
    "\n",
    "# these weights can be saved and loaded later in the 'Embedding()' layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.036169   -0.02938987  0.02602111  0.00319386 -0.03161726]\n",
      "\n",
      "\n",
      "\n",
      "[-0.01313028  0.02663325  0.01602728  0.04039905  0.01098454]\n"
     ]
    }
   ],
   "source": [
    "# testing embedding of 'nice' and 'amazing'\n",
    "print(weights[184])\n",
    "print(\"\\n\\n\")\n",
    "print(weights[407])\n",
    "\n",
    "# cosine similarity increases with vocabulary size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Saving Embeddings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nice\n",
      "food\n",
      "amazing\n",
      "restaurant\n",
      "too\n",
      "good\n",
      "horrible\n",
      "sevice\n",
      "highly\n",
      "disgusting\n",
      "never\n",
      "recommending\n",
      "this\n",
      "to\n",
      "anyone\n"
     ]
    }
   ],
   "source": [
    "# Set up a logs directory, so Tensorboard knows where to look for files\n",
    "log_dir = './Embeddings/'\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Save Labels separately on a line-by-line manner.\n",
    "with open(os.path.join(log_dir, 'metadata.tsv'), \"w\") as f:\n",
    "    \n",
    "    for words in reviews:\n",
    "        for subwords in words.split():\n",
    "            print(subwords)\n",
    "            f.write(\"{}\\n\".format(subwords))\n",
    "            \n",
    "#     for subwords in y:\n",
    "#         f.write(\"{}\\n\".format(subwords))\n",
    "  \n",
    "    # Fill in the rest of the labels with \"unknown\"\n",
    "    for unknown in range(1, vocab_size - len(y)):\n",
    "        f.write(\"unknown #{}\\n\".format(unknown))\n",
    "\n",
    "\n",
    "# Save the weights we want to analyse as a variable. Note that the first\n",
    "# value represents any unknown word, which is not in the metadata, so\n",
    "# we will remove that value.\n",
    "\n",
    "weights = tf.Variable(model.layers[0].get_weights()[0][1:])\n",
    "\n",
    "# Create a checkpoint from embedding, the filename and key are\n",
    "# name of the tensor.\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
    "\n",
    "# Set up config\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "\n",
    "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`\n",
    "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "projector.visualize_embeddings(log_dir, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 311), started 17:12:25 ago. (Use '!kill 311' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-45dd33e145a62e33\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-45dd33e145a62e33\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir /Embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 311"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
