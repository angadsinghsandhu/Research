{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code_full_connected.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W4V4T0EnUJ6"
      },
      "source": [
        "*DISEASE CLASSIFICATION TIME-SERIES* MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lC3sear-a2I"
      },
      "source": [
        "# imports\n",
        "import datetime\n",
        "from datetime import date\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from plotly import __version__\n",
        "%matplotlib inline\n",
        "\n",
        "import plotly.offline as pyo\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import iplot\n",
        "\n",
        "import cufflinks as cf\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
        "\n",
        "\n",
        "cf.go_offline()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99aA4jcSntxq"
      },
      "source": [
        "Uploading CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbgySciDnS7B"
      },
      "source": [
        "# File named in ./data.csv\n",
        "# NOTE: Please \"Allow 3rd Party Cookies\" in Chrome Options\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OBsb0FbovSj"
      },
      "source": [
        "print(uploaded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPAdkr-nht1K"
      },
      "source": [
        "# print(np.linspace(0, 1, df_size))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtFFfMsChXQ4"
      },
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "  \n",
        "df = pd.read_csv(io.BytesIO(uploaded['expanded.csv']))\n",
        "df_size = len(df.index)\n",
        "\n",
        "df[\"Index\"] = np.linspace(start = 0, stop = df_size-1, num = df_size, dtype = int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR3pVNWnovzs"
      },
      "source": [
        "# visualizing\n",
        "\n",
        "print(df)\n",
        "\n",
        "print(df[[\"RF\", \"MaxT\"]])\n",
        "\n",
        "print(df[\"RF\"][0])\n",
        "\n",
        "print(type(df['RF']))\n",
        "\n",
        "print(type(df['RF'].to_numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg1M0KAyq7CH"
      },
      "source": [
        "Visualizing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkynil-Nq6b7"
      },
      "source": [
        "# Creating Simple Dynamic Graph to see all data\n",
        "%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "fig = plt.figure(figsize=(23, 6), dpi=80)\n",
        "ax = plt.axes()\n",
        "\n",
        "# NOTE : Chane the value of var for any other header to get different results\n",
        "var = \"RF\"\n",
        "plt.plot(df['Date'].to_numpy(), df[var].to_numpy());"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZidGZWl2ajU"
      },
      "source": [
        "init_notebook_mode(connected=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRzuyiUt-i1S"
      },
      "source": [
        "# Create function for Colab\n",
        "def configure_plotly_browser_state():\n",
        "  import IPython\n",
        "  display(IPython.core.display.HTML('''\n",
        "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
        "        <script>\n",
        "          requirejs.config({\n",
        "            paths: {\n",
        "              base: '/static/base',\n",
        "              plotly: 'https://cdn.plot.ly/plotly-1.5.1.min.js?noext',\n",
        "            },\n",
        "          });\n",
        "        </script>\n",
        "  '''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WykreLP7-wsz"
      },
      "source": [
        "configure_plotly_browser_state()\n",
        "df.iplot(kind='line', x='Index', y=['RF'], color=['white'], \n",
        "theme='solar', mode='markers',title='Annual Rainfall in the city Peachtree City, GA')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei3RYC_7_XM3"
      },
      "source": [
        "configure_plotly_browser_state()\n",
        "df.iplot(kind='line',x='Index',y=['MinT', \"MaxT\"], color=['white', 'gold'], \n",
        "theme='solar', mode='markers',title='Annual Rainfall in the city Peachtree City, GA')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_9uaSQjG9QS"
      },
      "source": [
        "configure_plotly_browser_state()\n",
        "df.iplot(kind='line',x='Index',y=['RH-I', \"RH-II\"], color=['white', 'gold'], \n",
        "theme='solar', mode='markers',title='Annual Rainfall in the city Peachtree City, GA')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3859vofHA0U"
      },
      "source": [
        "configure_plotly_browser_state()\n",
        "df.iplot(kind='line',x='Index',y=['C2', \"SS\"], color=['white', 'gold'], \n",
        "theme='solar', mode='markers',title='Annual Rainfall in the city Peachtree City, GA')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPZ6NXRSHEIA"
      },
      "source": [
        "configure_plotly_browser_state()\n",
        "df.iplot(kind='line',x='Index',y=['WD1', \"WD2\", \"WS\"], color=['white', 'gold', \"red\"], \n",
        "theme='solar', mode='markers',title='Annual Rainfall in the city Peachtree City, GA')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxKBhq5kOiq5"
      },
      "source": [
        "Pre Processing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "192h3bwBPShP"
      },
      "source": [
        "# preproceessing data\n",
        "def one_hot_prob_dist(val):\n",
        "  if val == 0 :\n",
        "    return [1, 0, 0, 0]\n",
        "  elif val == 1 :\n",
        "    return [0, 1, 0, 0]\n",
        "  elif val == 2 :\n",
        "    return [0, 0, 1, 0]\n",
        "  elif val == 3 :\n",
        "    return [0, 0, 0, 1]\n",
        "  else :\n",
        "    print(val)\n",
        "    raise ValueError\n",
        "\n",
        "def create_timesteps(X, y, length, step, n_features):\n",
        "  if step > 1 :\n",
        "    # Create Timestep Data\n",
        "    X = X.reshape(length, 1, n_features)\n",
        "\n",
        "    # Num samples = length - step + 1\n",
        "    samples = length - step + 1\n",
        "\n",
        "    y = y[step-1:] \n",
        "\n",
        "    temp = np.empty(shape=[samples, step, n_features])\n",
        "    for i in range(samples):\n",
        "      temp[i] = X[i : i+step].reshape(1, step, n_features)\n",
        "    return temp, y\n",
        "  \n",
        "  return X, y\n",
        "\n",
        "def prepare_data(data, length, step, n_features):\n",
        "  # Dividing X and y\n",
        "  X = data[[\"RF\", \"MaxT\", \"MinT\", \"RH-I\", \"RH-II\", \"C2\", \"SS\", \"WD1\", \"WD2\", \"WS\"]]\n",
        "  y_temp = data[\"Disease\"]\n",
        "  y = []\n",
        "\n",
        "  # print(\"X & y : \", \"\\n\", X, \"\\n\", y_temp)\n",
        "\n",
        "  # Create Numpy arrays\n",
        "  X = X.to_numpy()\n",
        "  y_temp = y_temp.to_numpy()\n",
        "\n",
        "  for i in range(len(y_temp)):\n",
        "    arr = one_hot_prob_dist(y_temp[i])\n",
        "    y.append(arr)\n",
        "\n",
        "  y = np.array(y)\n",
        "\n",
        "  # print(\"X & y (in numpy) : \", \"\\n\", X, \"\\n\", y)\n",
        "  # print(\"X & y (shape) : \", X.shape, \", \", y.shape)\n",
        "\n",
        "  # Normalizing values\n",
        "  X = (X - X.min(0)) / X.ptp(0)\n",
        "  # y = (y - y.min(0)) / y.ptp(0)\n",
        "\n",
        "  # print(\"X & y (normalized) : \", \"\\n\", X, \"\\n\", y)\n",
        "\n",
        "  # reshaping data into 3D structure [example, timesteps, features]\n",
        "  X, y = create_timesteps(X, y, length, step, n_features)\n",
        "  \n",
        "  return X, y\n",
        "\n",
        "def split_data(X, y, ratio=0.98):\n",
        "  # Create X_test, X_train, y_test, y_train\n",
        "  if ratio > 1:\n",
        "    raise Error\n",
        "  else :\n",
        "    tot = X.shape[0]\n",
        "    div = round(tot*ratio)\n",
        "\n",
        "    # splitting\n",
        "    if step > 1:\n",
        "      X_train = X[:div, :, :]\n",
        "      X_test = X[div:, :, :]\n",
        "    else:\n",
        "      X_train = X[:div, :]\n",
        "      X_test = X[div:, :]\n",
        "    \n",
        "    y_train = y[:div]\n",
        "    y_test = y[div:]\n",
        "  \n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fBY-VqHPeNC"
      },
      "source": [
        "# defining data\n",
        "step = 1\n",
        "length = len(df.index)\n",
        "n_features = 10\n",
        "\n",
        "X, y = prepare_data(df, length, step, n_features)\n",
        "length = y.shape[0]\n",
        "\n",
        "print(\"X : \\n\", X.shape, \"\\n\\ny : \", y.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVlEJYBse07m"
      },
      "source": [
        "np.set_printoptions(precision=3)\n",
        "print(\"X : \\n\", X[:6], \"\\n\\ny : \", y[:6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOWzEgBWX12I"
      },
      "source": [
        "Shuffling Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1IJbWunX1o0"
      },
      "source": [
        "indices = np.arange(y.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "X = X[indices]\n",
        "y = y[indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ih97VRVXy2S"
      },
      "source": [
        "Split Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWPsh9oA2REG"
      },
      "source": [
        "X_train, y_train, X_test, y_test = split_data(X, y, ratio=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgM2iyaH4RM-"
      },
      "source": [
        "print(\"X_train : \", X_train[:10], \"\\n\\ny_test : \", y_train[:-10])\n",
        "print(\"\\n\\nX_train and y_test (shape) : \", X_train.shape, \", \", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGk2WmZt48tF"
      },
      "source": [
        "Training Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWSRdyXg48el"
      },
      "source": [
        "# impots\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.layers import SimpleRNN\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import GRU\n",
        "from tensorflow.keras.layers import RNN\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.utils import normalize, to_categorical\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7KplugJJNTx"
      },
      "source": [
        "Fully Connected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXwcrq06JNBO"
      },
      "source": [
        "# defining model\n",
        "model = Sequential()\n",
        "\n",
        "# model structure\n",
        "model.add(Dense(10, activation='relu', input_shape=(step, n_features)))\n",
        "# model.add(Dropout(0.3))\n",
        "# model.add(Flatten())\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer=Adam(learning_rate=0.00005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# model sumary\n",
        "print(model.summary())\n",
        "\n",
        "# train model\n",
        "epochs = 200\n",
        "history = model.fit(X_train, y_train, epochs=epochs, verbose=1)\n",
        "\n",
        "# validation_data=(X_test, y_test), batch_size=20,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFA3HSjxVN3n"
      },
      "source": [
        "# defining model\n",
        "model = Sequential()\n",
        "\n",
        "# model structure\n",
        "model.add(Dense(10, activation='relu', input_shape=(step, n_features)))\n",
        "# model.add(Dropout(0.3))\n",
        "# model.add(Flatten())\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer=Adam(learning_rate=0.005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# model sumary\n",
        "print(model.summary())\n",
        "\n",
        "# train model\n",
        "epochs = 200\n",
        "history = model.fit(X_train, y_train, epochs=epochs, verbose=1)\n",
        "\n",
        "# validation_data=(X_test, y_test), batch_size=20,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa134ot3-e4S"
      },
      "source": [
        "Predicting Data and Seeing results using Test Set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mILQRFlgegtt"
      },
      "source": [
        "# Evaluate the model on the test data using `evaluate`\n",
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate(X_test, y_test, batch_size=32)\n",
        "print(\"test loss, test acc:\", results)\n",
        "\n",
        "# Generate predictions (probabilities -- the output of the last layer)\n",
        "# on new data using `predict`\n",
        "num_tests = 10\n",
        "print(\"Generate predictions for 3 samples\")\n",
        "predictions = model.predict(X_test[:num_tests])\n",
        "print(\"predictions shape:\", predictions.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFo_NMdAesVh"
      },
      "source": [
        "for i in range(num_tests):\n",
        "  print(\"Test Value :\", y_test[i])\n",
        "  print(\"Predicted Value :\", predictions[i])\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjknt3ZEARyo"
      },
      "source": [
        "Visualizing Ouput"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtm419tBqKbY"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Add data\n",
        "# check for overfitting and underfitting\n",
        "loss = history.history['loss']\n",
        "acc = history.history['accuracy']\n",
        "epoch = np.arange(epochs) + 1\n",
        "\n",
        "# Note that even in the OO-style, we use `.pyplot.figure` to create the figure.\n",
        "fig, ax = plt.subplots()  # Create a figure and an axes.\n",
        "ax.plot(loss, epoch, label='loss')  # Plot some data on the axes.\n",
        "ax.plot(acc, epoch, label='accuracy')  # Plot more data on the axes...\n",
        "\n",
        "ax.set_xlabel('Epochs')  # Add an x-label to the axes.\n",
        "ax.set_ylabel('Score')  # Add a y-label to the axes.\n",
        "ax.set_title(\"Simple Plot\")  # Add a title to the axes.\n",
        "ax.legend()  # Add a legend.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZywBgzUj2VFr"
      },
      "source": [
        "**HANDLING Bi-DIRECTIONAL DATA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34Onq9js2kXm"
      },
      "source": [
        "Pre Processing Bi-Directional Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXjQ8G7wY6_k"
      },
      "source": [
        "def get_disease_count(values):\n",
        "  index_0 = 0\n",
        "  index_1 = 0\n",
        "  index_2 = 0\n",
        "  index_3 = 0\n",
        "\n",
        "  for val in values:\n",
        "    if val == 0:\n",
        "      index_0 += 1\n",
        "    elif val == 1:\n",
        "      index_1 += 1\n",
        "    elif val == 2:\n",
        "      index_2 += 1\n",
        "    else:\n",
        "      index_3 += 1\n",
        "\n",
        "  print(\"Number of 0s : \", index_0, \"\\nNumber of 1s : \", index_1, \"\\nNumber of 2s : \", index_2, \"\\nNumber of 3s : \", index_3)\n",
        "\n",
        "def get_disease_count_one_hot(values):\n",
        "  index_0 = 0\n",
        "  index_1 = 0\n",
        "  index_2 = 0\n",
        "  index_3 = 0\n",
        "\n",
        "  for val in values:\n",
        "    if val[0] == 1:\n",
        "      index_0 += 1\n",
        "    elif val[1] == 1:\n",
        "      index_1 += 1\n",
        "    elif val[2] == 1:\n",
        "      index_2 += 1\n",
        "    else:\n",
        "      index_3 += 1\n",
        "\n",
        "  print(\"Number of 0s : \", index_0, \"\\nNumber of 1s : \", index_1, \"\\nNumber of 2s : \", index_2, \"\\nNumber of 3s : \", index_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RQaRQ1jY3Tl"
      },
      "source": [
        "df = df.sort_values(by='Disease', ascending=False)\n",
        "print(df)\n",
        "get_disease_count(df['Disease'].to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9apsb8q2eDX"
      },
      "source": [
        "# preproceessing data\n",
        "def one_hot_prob_dist(val):\n",
        "  if val == 0 :\n",
        "    return [1, 0, 0, 0]\n",
        "  elif val == 1 :\n",
        "    return [0, 1, 0, 0]\n",
        "  elif val == 2 :\n",
        "    return [0, 0, 1, 0]\n",
        "  elif val == 3 :\n",
        "    return [0, 0, 0, 1]\n",
        "  else :\n",
        "    print(val)\n",
        "    raise ValueError\n",
        "\n",
        "def create_timesteps_bi(X, y, length, step, n_features):\n",
        "  if step > 1 :\n",
        "    # Create Timestep Data\n",
        "    X = X.reshape(length, 1, n_features)\n",
        "\n",
        "    # Num samples = length - step + 1\n",
        "    samples = length - step + 1\n",
        "\n",
        "    temp_x = np.empty(shape=[samples, step, n_features])\n",
        "    temp_y = np.empty(shape=[samples, step, 4])\n",
        "    for i in range(samples):\n",
        "      temp_x[i] = X[i : i+step].reshape(1, step, n_features)\n",
        "      temp_y[i] = y[i : i+step].reshape(1, step, 4)\n",
        "    return temp_x, temp_y\n",
        "  \n",
        "  return X, y\n",
        "\n",
        "def prepare_data_bi(data, length, step, n_features):\n",
        "  # Dividing X and y\n",
        "  X = data[[\"RF\", \"MaxT\", \"RH-I\", \"RH-II\", \"C2\", \"SS\", \"WD1\", \"WD2\", \"WS\"]]\n",
        "  y_temp = data[\"Disease\"]\n",
        "  y = []\n",
        "\n",
        "  # print(\"X & y : \", \"\\n\", X, \"\\n\", y_temp)\n",
        "\n",
        "  # Create Numpy arrays\n",
        "  X = X.to_numpy()\n",
        "  y_temp = y_temp.to_numpy()\n",
        "\n",
        "  for i in range(len(y_temp)):\n",
        "    arr = one_hot_prob_dist(y_temp[i])\n",
        "    y.append(arr)\n",
        "\n",
        "  y = np.array(y)\n",
        "\n",
        "  # print(\"X & y (in numpy) : \", \"\\n\", X, \"\\n\", y)\n",
        "  # print(\"X & y (shape) : \", X.shape, \", \", y.shape)\n",
        "\n",
        "  # Normalizing values\n",
        "  X = (X - X.min(0)) / X.ptp(0)\n",
        "  # y = (y - y.min(0)) / y.ptp(0)\n",
        "\n",
        "  # print(\"X & y (normalized) : \", \"\\n\", X, \"\\n\", y)\n",
        "\n",
        "  # reshaping data into 3D structure [example, timesteps, features]\n",
        "  X, y = create_timesteps_bi(X, y, length, step, n_features)\n",
        "  \n",
        "  return X, y\n",
        "\n",
        "def split_data_bi(X, y, ratio=0.98):\n",
        "  # Create X_test, X_train, y_test, y_train\n",
        "  if ratio > 1:\n",
        "    raise Error\n",
        "  else :\n",
        "    tot = X.shape[0]\n",
        "    div = round(tot*ratio)\n",
        "\n",
        "    # splitting\n",
        "    if step > 1:\n",
        "\n",
        "\n",
        "      X_train = X[:div, :, :]\n",
        "      y_train = y[:div, :, :]\n",
        "\n",
        "      X_test = X[div:, :, :]\n",
        "      y_test = y[div:, :, :]\n",
        "    else:\n",
        "      X_train = X[:div, :]\n",
        "      y_train = y[:div, :]\n",
        "\n",
        "      X_test = X[div:, :]\n",
        "      y_test = y[div:, :]\n",
        "\n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EDg-KDu2lqD"
      },
      "source": [
        "# defining data\n",
        "step = 1\n",
        "length = len(df.index)\n",
        "n_features = 9\n",
        "\n",
        "X_bi, y_bi = prepare_data_bi(df, length, step, n_features)\n",
        "length = y.shape[0]\n",
        "\n",
        "# print(\"X : \\n\", X.shape, \"\\n\\ny : \", y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkT2-3la3U95"
      },
      "source": [
        "np.set_printoptions(precision=3)\n",
        "print(\"X : \\n\", X_bi.shape, \"\\n\\ny : \", y_bi.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6IGPDktCzDz"
      },
      "source": [
        "Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_pBClMf3aW_"
      },
      "source": [
        "X_train_bi, y_train_bi, X_test_bi, y_test_bi = split_data_bi(X_bi, y_bi, ratio=0.62)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZdPaCli3uV7"
      },
      "source": [
        "print(\"X_train : \", X_train_bi[:10], \"\\n\\ny_test : \", y_train_bi[:-10])\n",
        "# for i in range(200):\n",
        "#   print(y_train_bi[i], \"\\n\")\n",
        "print(\"\\n\\nX_train and y_test (shape) : \", X_train_bi.shape, \", \", y_test_bi.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Houv-g8ydoG9"
      },
      "source": [
        "get_disease_count_one_hot(y_train_bi)\n",
        "print()\n",
        "get_disease_count_one_hot(y_test_bi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTQZ9xH8CwAf"
      },
      "source": [
        "Shuffle Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOsGgj5LCyyv"
      },
      "source": [
        "indices = np.arange(y_train_bi.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "X_train_bi = X_train_bi[indices]\n",
        "y_train_bi = y_train_bi[indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fnfo6RYo4Pth"
      },
      "source": [
        "Training Bidirectional Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuKSYPExfH4B"
      },
      "source": [
        "Fully Connected Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awMr4ATYfHk4"
      },
      "source": [
        "# defining model\n",
        "model = Sequential()\n",
        "\n",
        "# model structure\n",
        "# model.add(Flatten())\n",
        "\n",
        "model.add(Dense(100, activation='relu', input_shape=(step, n_features)))\n",
        "model.add(Dropout(0.5))\n",
        "# model.add(Dense(10, activation='relu', input_shape=(step, n_features)))\n",
        "# model.add(Dropout(0.3))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer=Adam(learning_rate=0.005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# model sumary\n",
        "print(model.summary())\n",
        "\n",
        "# train model\n",
        "epochs = 200\n",
        "history = model.fit(X_train_bi, y_train_bi, epochs=epochs, verbose=1)\n",
        "\n",
        "# validation_data=(X_test, y_test), batch_size=20,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Miui9WQa7x63"
      },
      "source": [
        "Predicting Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUNQ8Guq8kk7"
      },
      "source": [
        "# Evaluate the model on the test data using `evaluate`\n",
        "print(\"Evaluate on test data\")\n",
        "results_bi = model.evaluate(X_test_bi, y_test_bi, batch_size=32)\n",
        "print(\"test loss, test acc:\", results_bi)\n",
        "\n",
        "# Generate predictions (probabilities -- the output of the last layer)\n",
        "# on new data using `predict`\n",
        "num_tests_bi = 30\n",
        "print(\"Generate predictions for 3 samples\")\n",
        "predictions_bi = model.predict(X_train_bi[:num_tests_bi])\n",
        "print(\"predictions shape:\", predictions_bi.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQOsQTcC8lDc"
      },
      "source": [
        "for i in range(num_tests_bi):\n",
        "  print(\"Test Value :\\n\", y_train_bi[i])\n",
        "  print(\"Predicted Value :\\n\", predictions_bi[i])\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSAP6LSm7yPS"
      },
      "source": [
        "Visualizing Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPTQjMiM9Ehg"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Add data\n",
        "# check for overfitting and underfitting\n",
        "loss = history.history['loss']\n",
        "acc = history.history['accuracy']\n",
        "epoch = np.arange(epochs) + 1\n",
        "\n",
        "# Note that even in the OO-style, we use `.pyplot.figure` to create the figure.\n",
        "fig, ax = plt.subplots()  # Create a figure and an axes.\n",
        "ax.plot(loss, epoch, label='loss')  # Plot some data on the axes.\n",
        "ax.plot(acc, epoch, label='accuracy')  # Plot more data on the axes...\n",
        "\n",
        "ax.set_xlabel('Epochs')  # Add an x-label to the axes.\n",
        "ax.set_ylabel('Score')  # Add a y-label to the axes.\n",
        "ax.set_title(\"Simple Plot\")  # Add a title to the axes.\n",
        "ax.legend()  # Add a legend.\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}