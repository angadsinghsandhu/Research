{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_optimizer_eg2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W4V4T0EnUJ6"
      },
      "source": [
        "*DISEASE CLASSIFICATION TIME-SERIES* MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lC3sear-a2I"
      },
      "source": [
        "# imports\n",
        "import datetime\n",
        "from datetime import date\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from plotly import __version__\n",
        "%matplotlib inline\n",
        "\n",
        "import plotly.offline as pyo\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import iplot\n",
        "\n",
        "import cufflinks as cf\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
        "\n",
        "\n",
        "cf.go_offline()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99aA4jcSntxq"
      },
      "source": [
        "Uploading CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbgySciDnS7B"
      },
      "source": [
        "# File named in ./data.csv\n",
        "# NOTE: Please \"Allow 3rd Party Cookies\" in Chrome Options\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OBsb0FbovSj"
      },
      "source": [
        "print(uploaded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtFFfMsChXQ4"
      },
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "  \n",
        "df = pd.read_csv(io.BytesIO(uploaded['dataset_min.csv']))\n",
        "df_size = len(df.index)\n",
        "\n",
        "df[\"Index\"] = np.linspace(start = 0, stop = df_size-1, num = df_size, dtype = int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR3pVNWnovzs"
      },
      "source": [
        "# visualizing\n",
        "\n",
        "print(df.head().to_string())\n",
        "\n",
        "print(df[[\"RF\", \"MaxT\"]])\n",
        "\n",
        "print(df[\"RF\"][0])\n",
        "\n",
        "print(type(df['RF']))\n",
        "\n",
        "print(type(df['RF'].to_numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg1M0KAyq7CH"
      },
      "source": [
        "Visualizing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkynil-Nq6b7"
      },
      "source": [
        "# Creating Simple Dynamic Graph to see all data\n",
        "%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "fig = plt.figure(figsize=(23, 6), dpi=80)\n",
        "ax = plt.axes()\n",
        "\n",
        "# NOTE : Chane the value of var for any other header to get different results\n",
        "var = \"RF\"\n",
        "plt.plot(df['Date'].to_numpy(), df[var].to_numpy());"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZidGZWl2ajU"
      },
      "source": [
        "init_notebook_mode(connected=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRzuyiUt-i1S"
      },
      "source": [
        "# Create function for Colab\n",
        "def configure_plotly_browser_state():\n",
        "  import IPython\n",
        "  display(IPython.core.display.HTML('''\n",
        "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
        "        <script>\n",
        "          requirejs.config({\n",
        "            paths: {\n",
        "              base: '/static/base',\n",
        "              plotly: 'https://cdn.plot.ly/plotly-1.5.1.min.js?noext',\n",
        "            },\n",
        "          });\n",
        "        </script>\n",
        "  '''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WykreLP7-wsz"
      },
      "source": [
        "configure_plotly_browser_state()\n",
        "df.iplot(kind='line', x='Index', y=['RF'], color=['white'], \n",
        "theme='solar', mode='markers',title='Annual Rainfall in the city Peachtree City, GA')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei3RYC_7_XM3"
      },
      "source": [
        "configure_plotly_browser_state()\n",
        "df.iplot(kind='line',x='Index',y=['MinT', \"MaxT\"], color=['white', 'gold'], \n",
        "theme='solar', mode='markers',title='Annual Rainfall in the city Peachtree City, GA')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxKBhq5kOiq5"
      },
      "source": [
        "Pre Processing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "192h3bwBPShP"
      },
      "source": [
        "# preproceessing data\n",
        "def one_hot_prob_dist(val):\n",
        "  if val == 0 :\n",
        "    return [1, 0, 0, 0]\n",
        "  elif val == 1 :\n",
        "    return [0, 1, 0, 0]\n",
        "  elif val == 2 :\n",
        "    return [0, 0, 1, 0]\n",
        "  elif val == 3 :\n",
        "    return [0, 0, 0, 1]\n",
        "  else :\n",
        "    print(val)\n",
        "    raise ValueError\n",
        "\n",
        "def create_timesteps(X, y, length, step, n_features):\n",
        "  # Create Timestep Data\n",
        "  X = X.reshape(length, 1, n_features)\n",
        "\n",
        "  # Num samples = length - step + 1\n",
        "  samples = length - step + 1\n",
        "    \n",
        "  if step > 1 :\n",
        "    y = y[step-1:] \n",
        "\n",
        "    temp = np.empty(shape=[samples, step, n_features])\n",
        "    for i in range(samples):\n",
        "      temp[i] = X[i : i+step].reshape(1, step, n_features)\n",
        "    return temp, y\n",
        "  \n",
        "  return X, y\n",
        "\n",
        "def prepare_data(data, length, step, n_features):\n",
        "  # Dividing X and y\n",
        "  X = data[[\"RF\", \"MaxT\", \"MinT\", \"RH-I\", \"RH-II\", \"C1\", \"C2\", \"SS\", \"WD1\", \"WD2\"]]\n",
        "  y_temp = data[\"Disease\"]\n",
        "  y = []\n",
        "\n",
        "  # print(\"X & y : \", \"\\n\", X, \"\\n\", y_temp)\n",
        "\n",
        "  # Create Numpy arrays\n",
        "  X = X.to_numpy()\n",
        "  y_temp = y_temp.to_numpy()\n",
        "\n",
        "  for i in range(len(y_temp)):\n",
        "    arr = one_hot_prob_dist(y_temp[i])\n",
        "    y.append(arr)\n",
        "\n",
        "  y = np.array(y)\n",
        "\n",
        "  # print(\"X & y (in numpy) : \", \"\\n\", X, \"\\n\", y)\n",
        "  # print(\"X & y (shape) : \", X.shape, \", \", y.shape)\n",
        "\n",
        "  # Normalizing values\n",
        "  X = (X - X.min(0)) / X.ptp(0)\n",
        "  # y = (y - y.min(0)) / y.ptp(0)\n",
        "\n",
        "  # print(\"X & y (normalized) : \", \"\\n\", X, \"\\n\", y)\n",
        "\n",
        "  # reshaping data into 3D structure [example, timesteps, features]\n",
        "  X, y = create_timesteps(X, y, length, step, n_features)\n",
        "  \n",
        "  return X, y\n",
        "\n",
        "def split_data(X, y, ratio=0.98):\n",
        "  # Create X_test, X_train, y_test, y_train\n",
        "  if ratio > 1:\n",
        "    raise Error\n",
        "  else :\n",
        "    tot = X.shape[0]\n",
        "    div = round(tot*ratio)\n",
        "\n",
        "    # splitting\n",
        "    X_train = X[:div, :, :]\n",
        "    y_train = y[:div]\n",
        "\n",
        "    X_test = X[div:, :, :]\n",
        "    y_test = y[div:]\n",
        "  \n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fBY-VqHPeNC"
      },
      "source": [
        "# defining data\n",
        "step = 15\n",
        "length = len(df.index)\n",
        "n_features = 10\n",
        "\n",
        "X, y = prepare_data(df, length, step, n_features)\n",
        "length = y.shape[0]\n",
        "\n",
        "print(\"X : \\n\", X.shape, \"\\n\\ny : \", y.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVlEJYBse07m"
      },
      "source": [
        "np.set_printoptions(precision=3)\n",
        "print(\"X : \\n\", X[:6], \"\\n\\ny : \", y[:6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWPsh9oA2REG"
      },
      "source": [
        "X_train, y_train, X_test, y_test = split_data(X, y, ratio=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgM2iyaH4RM-"
      },
      "source": [
        "print(\"X_train : \", X_train[:10], \"\\n\\ny_test : \", y_train[:-10])\n",
        "print(\"\\n\\nX_train and y_test (shape) : \", X_train.shape, \", \", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGk2WmZt48tF"
      },
      "source": [
        "Training Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWSRdyXg48el"
      },
      "source": [
        "# impots\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.layers import SimpleRNN\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import GRU\n",
        "from tensorflow.keras.layers import RNN\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This class defines the API to add Ops to train a model. \n",
        "from tensorflow.python.ops import control_flow_ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.ops import state_ops\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.training import optimizer\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "TFCvv7hitR-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizer Class"
      ],
      "metadata": {
        "id": "G4KhQXrabvAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# basic Optimizer\n",
        "opti = Adam(learning_rate=0.00005)"
      ],
      "metadata": {
        "id": "6fbMKrm4buxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SGOptimizer(optimizer.Optimizer):\n",
        "    def __init__(self, learning_rate=0.01, name=\"SGOptimizer\", use_locking=False, **kwargs):\n",
        "        \"\"\"Call super().__init__() and use _set_hyper() to store hyperparameters\"\"\"\n",
        "        super(SGOptimizer, self).__init__(use_locking, name)\n",
        "        # self._set_hyper(\"learning_rate\", kwargs.get(\"lr\", learning_rate)) # handle lr=learning_rate\n",
        "        self._lr = learning_rate\n",
        "        self._is_first = True\n",
        "\n",
        "        # Tensor versions of the constructor arguments, created in _prepare().\n",
        "        self._lr_t = None\n",
        "      \n",
        "    def _prepare(self):\n",
        "        self._lr_t = ops.convert_to_tensor(self._lr, name=\"learning_rate\")\n",
        "\n",
        "    \n",
        "    def _create_slots(self, var_list):\n",
        "        \"\"\"For each model variable, create the optimizer variable associated with it.\n",
        "        TensorFlow calls these optimizer variables \"slots\".\n",
        "        For momentum optimization, we need one momentum slot per model variable.\n",
        "        \"\"\"\n",
        "        for var in var_list:\n",
        "            self._zeros_slot(var, \"pv\", self._name) #previous variable i.e. weight or bias\n",
        "        for var in var_list:\n",
        "            self._zeros_slot(var, \"pg\", self._name) #previous gradient\n",
        "\n",
        "\n",
        "\n",
        "    @tf.function\n",
        "    def _resource_apply_dense(self, grad, var):\n",
        "        \"\"\"Update the slots and perform one optimization step for one model variable\n",
        "        \"\"\"\n",
        "        var_dtype = var.dtype.base_dtype\n",
        "        lr_t = math_ops.cast(self._lr_t, var.dtype.base_dtype) # handle learning rate decay\n",
        "        new_var_m = var - grad * lr_t\n",
        "        pv_var = self.get_slot(var, \"pv\")\n",
        "        pg_var = self.get_slot(var, \"pg\")\n",
        "        \n",
        "        if self._is_first:\n",
        "            self._is_first = False\n",
        "            new_var = new_var_m\n",
        "        else:\n",
        "            cond = grad*pg_var >= 0\n",
        "            print(cond)\n",
        "            avg_weights = (pv_var + var)/2.0\n",
        "            new_var = tf.where(cond, new_var_m, avg_weights)\n",
        "        pv_var.assign(var)\n",
        "        pg_var.assign(grad)\n",
        "        var.assign(new_var)\n",
        "\n",
        "    def _resource_apply_sparse(self, grad, var):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {\n",
        "            **base_config,\n",
        "            \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n",
        "        }\n",
        "\n",
        "\n",
        "    def _resource_apply_sparse(self, grad, var):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {\n",
        "            **base_config,\n",
        "            \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n",
        "            \"decay\": self._serialize_hyperparameter(\"decay\"),\n",
        "            \"momentum\": self._serialize_hyperparameter(\"momentum\"),\n",
        "        }"
      ],
      "metadata": {
        "id": "i05fAl-YtEls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New Custom Function\n",
        "opti = SGOptimizer(learning_rate=0.00005)"
      ],
      "metadata": {
        "id": "4DsYP0l1tflU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "New TensorFlow Session"
      ],
      "metadata": {
        "id": "hl8epibisR4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "pFzs1QU7sRsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fonq7c7nryzz"
      },
      "source": [
        "Vanilla LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD85DM6L5KJP"
      },
      "source": [
        "# defining model\n",
        "model = Sequential()\n",
        "\n",
        "# model structure\n",
        "model.add(LSTM(30, activation='relu', input_shape=(step, n_features)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer=opti, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# model sumary\n",
        "print(model.summary())\n",
        "\n",
        "# train model\n",
        "epochs = 100\n",
        "history = model.fit(X_train, y_train, epochs=epochs, verbose=1)\n",
        "\n",
        "# validation_data=(X_test, y_test), batch_size=20,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa134ot3-e4S"
      },
      "source": [
        "Predicting Data and Seeing results using Test Set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mILQRFlgegtt"
      },
      "source": [
        "# Evaluate the model on the test data using `evaluate`\n",
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate(X_test, y_test, batch_size=32)\n",
        "print(\"test loss, test acc:\", results)\n",
        "\n",
        "# Generate predictions (probabilities -- the output of the last layer)\n",
        "# on new data using `predict`\n",
        "num_tests = 10\n",
        "print(\"Generate predictions for 3 samples\")\n",
        "predictions = model.predict(X_test[:num_tests])\n",
        "print(\"predictions shape:\", predictions.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFo_NMdAesVh"
      },
      "source": [
        "for i in range(num_tests):\n",
        "  print(\"Test Value :\", y_test[i])\n",
        "  print(\"Predicted Value :\", predictions[i])\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjknt3ZEARyo"
      },
      "source": [
        "Visualizing Ouput"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtm419tBqKbY"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Add data\n",
        "# check for overfitting and underfitting\n",
        "loss = history.history['loss']\n",
        "acc = history.history['accuracy']\n",
        "epoch = np.arange(epochs) + 1\n",
        "\n",
        "# Note that even in the OO-style, we use `.pyplot.figure` to create the figure.\n",
        "fig, ax = plt.subplots()  # Create a figure and an axes.\n",
        "ax.plot(loss, epoch, label='loss')  # Plot some data on the axes.\n",
        "ax.plot(acc, epoch, label='accuracy')  # Plot more data on the axes...\n",
        "\n",
        "ax.set_xlabel('Epochs')  # Add an x-label to the axes.\n",
        "ax.set_ylabel('Score')  # Add a y-label to the axes.\n",
        "ax.set_title(\"Simple Plot\")  # Add a title to the axes.\n",
        "ax.legend()  # Add a legend.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}