{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "optimizer_built_classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W4V4T0EnUJ6"
      },
      "source": [
        "*DISEASE CLASSIFICATION TIME-SERIES* MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lC3sear-a2I"
      },
      "source": [
        "# imports\n",
        "import datetime\n",
        "from datetime import date\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from plotly import __version__\n",
        "%matplotlib inline\n",
        "\n",
        "import plotly.offline as pyo\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import iplot\n",
        "\n",
        "import cufflinks as cf\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
        "\n",
        "\n",
        "cf.go_offline()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99aA4jcSntxq"
      },
      "source": [
        "Uploading CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbgySciDnS7B"
      },
      "source": [
        "# File named in ./data.csv\n",
        "# NOTE: Please \"Allow 3rd Party Cookies\" in Chrome Options\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OBsb0FbovSj"
      },
      "source": [
        "print(uploaded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtFFfMsChXQ4"
      },
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "  \n",
        "df = pd.read_csv(io.BytesIO(uploaded['dataset_min.csv']))\n",
        "df_size = len(df.index)\n",
        "\n",
        "df[\"Index\"] = np.linspace(start = 0, stop = df_size-1, num = df_size, dtype = int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR3pVNWnovzs"
      },
      "source": [
        "# visualizing\n",
        "\n",
        "print(df.head().to_string())\n",
        "\n",
        "print(df[[\"RF\", \"MaxT\"]])\n",
        "\n",
        "print(df[\"RF\"][0])\n",
        "\n",
        "print(type(df['RF']))\n",
        "\n",
        "print(type(df['RF'].to_numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg1M0KAyq7CH"
      },
      "source": [
        "Visualizing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkynil-Nq6b7"
      },
      "source": [
        "# Creating Simple Dynamic Graph to see all data\n",
        "%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "fig = plt.figure(figsize=(23, 6), dpi=80)\n",
        "ax = plt.axes()\n",
        "\n",
        "# NOTE : Chane the value of var for any other header to get different results\n",
        "var = \"RF\"\n",
        "plt.plot(df['Date'].to_numpy(), df[var].to_numpy());"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZidGZWl2ajU"
      },
      "source": [
        "init_notebook_mode(connected=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRzuyiUt-i1S"
      },
      "source": [
        "# Create function for Colab\n",
        "def configure_plotly_browser_state():\n",
        "  import IPython\n",
        "  display(IPython.core.display.HTML('''\n",
        "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
        "        <script>\n",
        "          requirejs.config({\n",
        "            paths: {\n",
        "              base: '/static/base',\n",
        "              plotly: 'https://cdn.plot.ly/plotly-1.5.1.min.js?noext',\n",
        "            },\n",
        "          });\n",
        "        </script>\n",
        "  '''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WykreLP7-wsz"
      },
      "source": [
        "configure_plotly_browser_state()\n",
        "df.iplot(kind='line', x='Index', y=['RF'], color=['white'], \n",
        "theme='solar', mode='markers',title='Annual Rainfall in the city Peachtree City, GA')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei3RYC_7_XM3"
      },
      "source": [
        "configure_plotly_browser_state()\n",
        "df.iplot(kind='line',x='Index',y=['MinT', \"MaxT\"], color=['white', 'gold'], \n",
        "theme='solar', mode='markers',title='Annual Rainfall in the city Peachtree City, GA')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxKBhq5kOiq5"
      },
      "source": [
        "Pre Processing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "192h3bwBPShP"
      },
      "source": [
        "# preproceessing data\n",
        "def one_hot_prob_dist(val):\n",
        "  if val == 0 :\n",
        "    return [1, 0, 0, 0]\n",
        "  elif val == 1 :\n",
        "    return [0, 1, 0, 0]\n",
        "  elif val == 2 :\n",
        "    return [0, 0, 1, 0]\n",
        "  elif val == 3 :\n",
        "    return [0, 0, 0, 1]\n",
        "  else :\n",
        "    print(val)\n",
        "    raise ValueError\n",
        "\n",
        "def create_timesteps(X, y, length, step, n_features):\n",
        "  # Create Timestep Data\n",
        "  X = X.reshape(length, 1, n_features)\n",
        "\n",
        "  # Num samples = length - step + 1\n",
        "  samples = length - step + 1\n",
        "    \n",
        "  if step > 1 :\n",
        "    y = y[step-1:] \n",
        "\n",
        "    temp = np.empty(shape=[samples, step, n_features])\n",
        "    for i in range(samples):\n",
        "      temp[i] = X[i : i+step].reshape(1, step, n_features)\n",
        "    return temp, y\n",
        "  \n",
        "  return X, y\n",
        "\n",
        "def prepare_data(data, length, step, n_features):\n",
        "  # Dividing X and y\n",
        "  X = data[[\"RF\", \"MaxT\", \"MinT\", \"RH-I\", \"RH-II\", \"C1\", \"C2\", \"SS\", \"WD1\", \"WD2\"]]\n",
        "  y_temp = data[\"Disease\"]\n",
        "  y = []\n",
        "\n",
        "  # print(\"X & y : \", \"\\n\", X, \"\\n\", y_temp)\n",
        "\n",
        "  # Create Numpy arrays\n",
        "  X = X.to_numpy()\n",
        "  y_temp = y_temp.to_numpy()\n",
        "\n",
        "  for i in range(len(y_temp)):\n",
        "    arr = one_hot_prob_dist(y_temp[i])\n",
        "    y.append(arr)\n",
        "\n",
        "  y = np.array(y)\n",
        "\n",
        "  # print(\"X & y (in numpy) : \", \"\\n\", X, \"\\n\", y)\n",
        "  # print(\"X & y (shape) : \", X.shape, \", \", y.shape)\n",
        "\n",
        "  # Normalizing values\n",
        "  X = (X - X.min(0)) / X.ptp(0)\n",
        "  # y = (y - y.min(0)) / y.ptp(0)\n",
        "\n",
        "  # print(\"X & y (normalized) : \", \"\\n\", X, \"\\n\", y)\n",
        "\n",
        "  # reshaping data into 3D structure [example, timesteps, features]\n",
        "  X, y = create_timesteps(X, y, length, step, n_features)\n",
        "  \n",
        "  return X, y\n",
        "\n",
        "def split_data(X, y, ratio=0.98):\n",
        "  # Create X_test, X_train, y_test, y_train\n",
        "  if ratio > 1:\n",
        "    raise Error\n",
        "  else :\n",
        "    tot = X.shape[0]\n",
        "    div = round(tot*ratio)\n",
        "\n",
        "    # splitting\n",
        "    X_train = X[:div, :, :]\n",
        "    y_train = y[:div]\n",
        "\n",
        "    X_test = X[div:, :, :]\n",
        "    y_test = y[div:]\n",
        "  \n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fBY-VqHPeNC"
      },
      "source": [
        "# defining data\n",
        "step = 15\n",
        "length = len(df.index)\n",
        "n_features = 10\n",
        "\n",
        "X, y = prepare_data(df, length, step, n_features)\n",
        "length = y.shape[0]\n",
        "\n",
        "print(\"X : \\n\", X.shape, \"\\n\\ny : \", y.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVlEJYBse07m"
      },
      "source": [
        "np.set_printoptions(precision=3)\n",
        "print(\"X : \\n\", X[:6], \"\\n\\ny : \", y[:6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWPsh9oA2REG"
      },
      "source": [
        "X_train, y_train, X_test, y_test = split_data(X, y, ratio=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgM2iyaH4RM-"
      },
      "source": [
        "print(\"X_train : \", X_train[:10], \"\\n\\ny_test : \", y_train[:-10])\n",
        "print(\"\\n\\nX_train and y_test (shape) : \", X_train.shape, \", \", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGk2WmZt48tF"
      },
      "source": [
        "Training Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWSRdyXg48el"
      },
      "source": [
        "# impots\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.layers import SimpleRNN\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import GRU\n",
        "from tensorflow.keras.layers import RNN\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops import control_flow_ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.ops import state_ops\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.training import optimizer\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "AqiSmod62sMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizer Class"
      ],
      "metadata": {
        "id": "G4KhQXrabvAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base Optimizer\n",
        "opti = Adam(learning_rate=0.00005)"
      ],
      "metadata": {
        "id": "6fbMKrm4buxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "baisc functions in optimizer class\n",
        "\n",
        "```\n",
        "def _create_slots(self, var_list):\n",
        "     # Create slots for allocation and later management of additional \n",
        "     # variables associated with the variables to train.\n",
        "     # for example: the first and second moments.\n",
        "     '''\n",
        "     for v in var_list:\n",
        "     self._zeros_slot(v, \"m\", self._name)\n",
        "     self._zeros_slot(v, \"v\", self._name)\n",
        "     '''\n",
        " def _apply_dense(self, grad, var):\n",
        "     #define your favourite variable update\n",
        "     # for example:\n",
        "     '''\n",
        "     # Here we apply gradient descents by substracting the variables \n",
        "     # with the gradient times the learning_rate (defined in __init__)\n",
        "     var_update = state_ops.assign_sub(var, self.learning_rate * grad) \n",
        "     '''\n",
        "     #The trick is now to pass the Ops in the control_flow_ops and \n",
        "     # eventually groups any particular computation of the slots your \n",
        "     # wish to keep track of:\n",
        "     # for example:    \n",
        "     '''\n",
        "     m_t = ...m... #do something with m and grad\n",
        "     v_t = ...v... # do something with v and grad\n",
        "     '''\n",
        "  return control_flow_ops.group(*[var_update, m_t, v_t])\n",
        "```"
      ],
      "metadata": {
        "id": "DLtpZr_k3p81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PowerSign(optimizer.Optimizer):\n",
        "    \"\"\"Implementation of PowerSign.\n",
        "    See [Bello et. al., 2017](https://arxiv.org/abs/1709.07417)\n",
        "    @@__init__\n",
        "    \"\"\"\n",
        "    def __init__(self, learning_rate=0.001,alpha=0.01,beta=0.5, use_locking=False, name=\"PowerSign\"):\n",
        "        super(PowerSign, self).__init__(use_locking, name)\n",
        "        self._lr = learning_rate\n",
        "        self._alpha = alpha\n",
        "        self._beta = beta\n",
        "        \n",
        "        # Tensor versions of the constructor arguments, created in _prepare().\n",
        "        self._lr_t = None\n",
        "        self._alpha_t = None\n",
        "        self._beta_t = None\n",
        "\n",
        "    def _prepare(self):\n",
        "        self._lr_t = ops.convert_to_tensor(self._lr, name=\"learning_rate\")\n",
        "        self._alpha_t = ops.convert_to_tensor(self._beta, name=\"alpha_t\")\n",
        "        self._beta_t = ops.convert_to_tensor(self._beta, name=\"beta_t\")\n",
        "\n",
        "    def _create_slots(self, var_list):\n",
        "        # Create slots for the first and second moments.\n",
        "        for v in var_list:\n",
        "            self._zeros_slot(v, \"m\", self._name)\n",
        "\n",
        "    def _apply_dense(self, grad, var):\n",
        "        lr_t = math_ops.cast(self._lr_t, var.dtype.base_dtype)\n",
        "        alpha_t = math_ops.cast(self._alpha_t, var.dtype.base_dtype)\n",
        "        beta_t = math_ops.cast(self._beta_t, var.dtype.base_dtype)\n",
        "\n",
        "        eps = 1e-7 #cap for moving average\n",
        "        \n",
        "        m = self.get_slot(var, \"m\")\n",
        "        m_t = m.assign(tf.maximum(beta_t * m + eps, tf.abs(grad)))\n",
        "\n",
        "        var_update = state_ops.assign_sub(var, lr_t*grad*tf.exp( tf.log(alpha_t)*tf.sign(grad)*tf.sign(m_t))) #Update 'ref' by subtracting 'value\n",
        "        #Create an op that groups multiple operations.\n",
        "        #When this op finishes, all ops in input have finished\n",
        "        return control_flow_ops.group(*[var_update, m_t])\n",
        "    \n",
        "    def _apply_sparse(self, grad, var):\n",
        "        raise NotImplementedError(\"Sparse gradient updates are not supported.\")"
      ],
      "metadata": {
        "id": "6qvoPl9A24z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AddSign(optimizer.Optimizer):\n",
        "    \"\"\"Implementation of AddSign.\n",
        "    See [Bello et. al., 2017](https://arxiv.org/abs/1709.07417)\n",
        "    @@__init__\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, learning_rate=1.001,alpha=0.01,beta=0.5, use_locking=False, name=\"AddSign\"):\n",
        "        super(AddSign, self).__init__(use_locking, name)\n",
        "        self._lr = learning_rate\n",
        "        self._alpha = alpha\n",
        "        self._beta = beta\n",
        "        \n",
        "        # Tensor versions of the constructor arguments, created in _prepare().\n",
        "        self._lr_t = None\n",
        "        self._alpha_t = None\n",
        "        self._beta_t = None\n",
        "      \n",
        "    def _prepare(self):\n",
        "        self._lr_t = ops.convert_to_tensor(self._lr, name=\"learning_rate\")\n",
        "        self._alpha_t = ops.convert_to_tensor(self._beta, name=\"beta_t\")\n",
        "        self._beta_t = ops.convert_to_tensor(self._beta, name=\"beta_t\")\n",
        "\n",
        "    def _create_slots(self, var_list):\n",
        "        # Create slots for the first and second moments.\n",
        "        for v in var_list:\n",
        "            self._zeros_slot(v, \"m\", self._name)\n",
        "\n",
        "    def _apply_dense(self, grad, var):\n",
        "        lr_t = math_ops.cast(self._lr_t, var.dtype.base_dtype)\n",
        "        beta_t = math_ops.cast(self._beta_t, var.dtype.base_dtype)\n",
        "        alpha_t = math_ops.cast(self._alpha_t, var.dtype.base_dtype)\n",
        "    \n",
        "        eps = 1e-7 #cap for moving average\n",
        "        \n",
        "        m = self.get_slot(var, \"m\")\n",
        "        m_t = m.assign(tf.maximum(beta_t * m + eps, tf.abs(grad)))\n",
        "        \n",
        "        var_update = state_ops.assign_sub(var, lr_t*grad*(1.0+alpha_t*tf.sign(grad)*tf.sign(m_t) ) )\n",
        "        #Create an op that groups multiple operations\n",
        "        #When this op finishes, all ops in input have finished\n",
        "        return control_flow_ops.group(*[var_update, m_t])\n",
        "\n",
        "    def _apply_sparse(self, grad, var):\n",
        "        lr_t = math_ops.cast(self._lr_t, var.dtype.base_dtype)\n",
        "        beta_t = math_ops.cast(self._beta_t, var.dtype.base_dtype)\n",
        "        alpha_t = math_ops.cast(self._alpha_t, var.dtype.base_dtype)\n",
        "    \n",
        "        eps = 1e-7 #cap for moving average\n",
        "        \n",
        "        m = self.get_slot(var, \"m\")\n",
        "        m_t = m.assign(tf.maximum(beta_t * m + eps, tf.abs(grad)))\n",
        "        \n",
        "        var_update = state_ops.assign_sub(var, lr_t*grad*(1.0+alpha_t*tf.sign(grad)*tf.sign(m_t) ) )\n",
        "        #Create an op that groups multiple operations\n",
        "        #When this op finishes, all ops in input have finished\n",
        "        return control_flow_ops.group(*[var_update, m_t])\n",
        "\n",
        "    def _resource_apply_dense(self, grad, var):\n",
        "        lr_t = math_ops.cast(self._lr_t, var.dtype.base_dtype)\n",
        "        beta_t = math_ops.cast(self._beta_t, var.dtype.base_dtype)\n",
        "        alpha_t = math_ops.cast(self._alpha_t, var.dtype.base_dtype)\n",
        "    \n",
        "        eps = 1e-7 #cap for moving average\n",
        "        \n",
        "        m = self.get_slot(var, \"m\")\n",
        "        m_t = m.assign(tf.maximum(beta_t * m + eps, tf.abs(grad)))\n",
        "        \n",
        "        var_update = state_ops.assign_sub(var, lr_t*grad*(1.0+alpha_t*tf.sign(grad)*tf.sign(m_t) ) )\n",
        "        #Create an op that groups multiple operations\n",
        "        #When this op finishes, all ops in input have finished\n",
        "        return control_flow_ops.group(*[var_update, m_t])"
      ],
      "metadata": {
        "id": "ebVoBtGo25Yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RosenbrockOpt(optimizer,MAX_EPOCHS = 4000, MAX_STEP = 100):\n",
        "  '''\n",
        "\treturns distance of each step*MAX_STEP w.r.t minimum (1,1)\n",
        "\t'''\n",
        "\n",
        "  x1_data = tf.Variable(initial_value=tf.random_uniform([1], minval=-3, maxval=3,seed=0),name='x1')\n",
        "  x2_data = tf.Variable(initial_value=tf.random_uniform([1], minval=-3, maxval=3,seed=1), name='x2')\n",
        "\n",
        "  y = tf.add(tf.pow(tf.subtract(1.0, x1_data), 2.0),\n",
        "  tf.multiply(100.0, tf.pow(tf.subtract(x2_data, tf.pow(x1_data, 2.0)), 2.0)), 'y')\n",
        "\n",
        "  global_step_tensor = tf.Variable(0, trainable=False, name='global_step')\n",
        "\n",
        "  train = optimizer.minimize(y,global_step=global_step_tensor)\n",
        "\n",
        "  sess = tf.Session()\n",
        "\n",
        "  init = tf.global_variables_initializer()#tf.initialize_all_variables()\n",
        "  sess.run(init)\n",
        "\n",
        "  minx = 1.0\n",
        "  miny = 1.0\n",
        "\n",
        "  distance = []\n",
        "  xx_ = sess.run(x1_data)\n",
        "  yy_ = sess.run(x2_data)\n",
        "  print(0,xx_,yy_,np.sqrt((minx-xx_)**2+(miny-yy_)**2))\n",
        "\n",
        "  for step in range(MAX_EPOCHS):\n",
        "    _, xx_, yy_, zz_ = sess.run([train,x1_data,x2_data,y])\n",
        "    if step % MAX_STEP == 0:\n",
        "      print(step+1, xx_,yy_, zz_)\n",
        "      distance += [ np.sqrt((minx-xx_)**2+(miny-yy_)**2)]\n",
        "    sess.close()\n",
        "    return distance"
      ],
      "metadata": {
        "id": "u-f5TEfG7TZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New Optimizer\n",
        "opti = AddSign(learning_rate=0.00005)"
      ],
      "metadata": {
        "id": "RaSx8i4c34Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fonq7c7nryzz"
      },
      "source": [
        "Vanilla LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD85DM6L5KJP"
      },
      "source": [
        "# defining model\n",
        "model = Sequential()\n",
        "\n",
        "# model structure\n",
        "model.add(LSTM(30, activation='relu', input_shape=(step, n_features)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer=opti, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# model sumary\n",
        "print(model.summary())\n",
        "\n",
        "# train model\n",
        "epochs = 100\n",
        "history = model.fit(X_train, y_train, epochs=epochs, verbose=1)\n",
        "\n",
        "# validation_data=(X_test, y_test), batch_size=20,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa134ot3-e4S"
      },
      "source": [
        "Predicting Data and Seeing results using Test Set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mILQRFlgegtt"
      },
      "source": [
        "# Evaluate the model on the test data using `evaluate`\n",
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate(X_test, y_test, batch_size=32)\n",
        "print(\"test loss, test acc:\", results)\n",
        "\n",
        "# Generate predictions (probabilities -- the output of the last layer)\n",
        "# on new data using `predict`\n",
        "num_tests = 10\n",
        "print(\"Generate predictions for 3 samples\")\n",
        "predictions = model.predict(X_test[:num_tests])\n",
        "print(\"predictions shape:\", predictions.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFo_NMdAesVh"
      },
      "source": [
        "for i in range(num_tests):\n",
        "  print(\"Test Value :\", y_test[i])\n",
        "  print(\"Predicted Value :\", predictions[i])\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjknt3ZEARyo"
      },
      "source": [
        "Visualizing Ouput"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtm419tBqKbY"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Add data\n",
        "# check for overfitting and underfitting\n",
        "loss = history.history['loss']\n",
        "acc = history.history['accuracy']\n",
        "epoch = np.arange(epochs) + 1\n",
        "\n",
        "# Note that even in the OO-style, we use `.pyplot.figure` to create the figure.\n",
        "fig, ax = plt.subplots()  # Create a figure and an axes.\n",
        "ax.plot(loss, epoch, label='loss')  # Plot some data on the axes.\n",
        "ax.plot(acc, epoch, label='accuracy')  # Plot more data on the axes...\n",
        "\n",
        "ax.set_xlabel('Epochs')  # Add an x-label to the axes.\n",
        "ax.set_ylabel('Score')  # Add a y-label to the axes.\n",
        "ax.set_title(\"Simple Plot\")  # Add a title to the axes.\n",
        "ax.legend()  # Add a legend.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}